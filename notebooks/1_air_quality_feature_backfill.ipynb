{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f139ba67",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 01: Feature Backfill for Air Quality Data</span>\n",
    "\n",
    "\n",
    "## üóíÔ∏è You have the following tasks\n",
    "1. Choose an Air Quality Sensor\n",
    "2. Update the country, city, and street information to point to YOUR chosen Air Quality Sensor\n",
    "3. Download historical measures for your Air Quality Sensor as a CSV file\n",
    "4. Update the path of the CSV file in this notebook to point to the one that you downloaded\n",
    "5. Create an account on www.hopsworks.ai and get your HOPSWORKS_API_KEY\n",
    "6. Run this notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0f447120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f1a49d6-9cd2-4246-b0ca-1058672e4848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-05 22:44:34,262 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-11-05 22:44:34,268 INFO: Initializing external client\n",
      "2025-11-05 22:44:34,269 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-11-05 22:44:34,989 WARNING: UserWarning: The installed hopsworks client version 4.4.2 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-05 22:44:35,957 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279137\n"
     ]
    }
   ],
   "source": [
    "dotenv.load_dotenv()\n",
    "project = hopsworks.login(engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9145f0b7-d961-41f7-aebe-741dbf00784c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found AQICN_API_KEY: 708f4173a90a3315ba6464933d6964b5bc6fc765\n",
      "Replacing existing AQICN_API_KEY\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Secret('AQICN_API_KEY', 'PRIVATE')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "AQICN_API_KEY = os.getenv(\"AQICN_API_KEY\")\n",
    "\n",
    "\n",
    "print(f\"Found AQICN_API_KEY: {AQICN_API_KEY}\")\n",
    "\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "# Replace any existing secret with the new value\n",
    "secret = secrets.get_secret(\"AQICN_API_KEY\")\n",
    "if secret is not None:\n",
    "    secret.delete()\n",
    "    print(\"Replacing existing AQICN_API_KEY\")\n",
    "\n",
    "secrets.create_secret(\"AQICN_API_KEY\", AQICN_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60cba088",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_id_cental = 1666\n",
    "sensor_id_east = 1664\n",
    "sensor_id_west = 1665\n",
    "sensor_id_north = 1662\n",
    "sensor_id_south = 1663\n",
    "\n",
    "sensor_id = sensor_id_cental\n",
    "\n",
    "url = f\"https://api.waqi.info/feed/@{sensor_id}/?token={AQICN_API_KEY}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "else:\n",
    "    print(\"Failed to retrieve data. Status Code:\", response.status_code)\n",
    "    raise requests.exceptions.RequestException(response.status_code)\n",
    "\n",
    "if data['status'] != 'ok':\n",
    "    raise Exception(f\"Error: {data['status']}\")\n",
    "\n",
    "aqi_data = data['data']\n",
    "aq_today_df = pd.DataFrame()\n",
    "aq_today_df['pm25'] = [aqi_data['iaqi'].get('pm25', {}).get('v', None)]\n",
    "aq_today_df['pm25'] = aq_today_df['pm25'].astype('float32')\n",
    "\n",
    "aq_today_df['sensor_id'] = sensor_id\n",
    "aq_today_df['city'] = \"Singapore\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "432fac7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm25</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.0</td>\n",
       "      <td>1666</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pm25  sensor_id       city\n",
       "0  85.0       1666  Singapore"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aq_today_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc3a1212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>pm10</th>\n",
       "      <th>o3</th>\n",
       "      <th>no2</th>\n",
       "      <th>so2</th>\n",
       "      <th>co</th>\n",
       "      <th>psi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>63.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>47.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>50.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>71.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>2015-06-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4314</th>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4315</th>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4316</th>\n",
       "      <td>2014-07-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4318 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  pm25  pm10    o3   no2  so2   co   psi\n",
       "0    2025-11-01  63.0  27.0  13.0   NaN  1.0  3.0   NaN\n",
       "1    2025-11-02  47.0  24.0  10.0   NaN  2.0  3.0   NaN\n",
       "2    2025-11-03  50.0  30.0  23.0   NaN  3.0  3.0   NaN\n",
       "3    2025-11-04  71.0  32.0  15.0   NaN  2.0  3.0   NaN\n",
       "4    2025-11-05  68.0   NaN   NaN   NaN  NaN  NaN   NaN\n",
       "...         ...   ...   ...   ...   ...  ...  ...   ...\n",
       "4313 2015-06-29   NaN  23.0  21.0  13.0  3.0  5.0  60.0\n",
       "4314 2015-06-30   NaN  27.0  10.0  20.0  3.0  5.0  58.0\n",
       "4315 2014-12-31   NaN  23.0  34.0  16.0  3.0  1.0   NaN\n",
       "4316 2014-07-20   NaN  17.0  14.0   7.0  6.0  3.0  47.0\n",
       "4317 2013-12-31   NaN  27.0  17.0   7.0  2.0  5.0  29.0\n",
       "\n",
       "[4318 rows x 8 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = \"../data/central,-singapore-air-quality.csv\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(csv_file,  parse_dates=['date'], skipinitialspace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd20c859-ef3c-4b54-bbcb-83898afefa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-05 22:44:38,832 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2025-11-05 22:44:38,834 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "2025-11-05 22:44:38,836 WARNING: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_aq = df[['date', 'pm25']]\n",
    "df_aq['pm25'] = df_aq['pm25'].astype('float32')\n",
    "df_aq['city'] = \"Singapore\"\n",
    "df_aq['sensor_id'] = sensor_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f13a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4318 entries, 0 to 4317\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   date       4318 non-null   datetime64[ns]\n",
      " 1   pm25       4285 non-null   float32       \n",
      " 2   city       4318 non-null   object        \n",
      " 3   sensor_id  4318 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float32(1), int64(1), object(1)\n",
      "memory usage: 118.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Cast the pm25 column to be a float32 data type\n",
    "df_aq.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "37b0a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aq=df_aq[df_aq[\"date\"] >= \"2016-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "05082a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4285   2024-12-31\n",
       "4286   2020-03-31\n",
       "4287   2019-12-31\n",
       "4288   2018-12-31\n",
       "4289   2018-03-31\n",
       "4290   2017-09-10\n",
       "4291   2016-01-03\n",
       "Name: date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter where pm25 is null and sort descending by date\n",
    "null_dates = (\n",
    "    df_aq.loc[df_aq['pm25'].isna(), 'date']\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "null_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e89f9213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>city</th>\n",
       "      <th>sensor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577</th>\n",
       "      <td>2016-03-28</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3578</th>\n",
       "      <td>2016-03-29</td>\n",
       "      <td>104.0</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3579</th>\n",
       "      <td>2016-03-30</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3580</th>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>104.0</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3673</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3582 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   pm25       city  sensor_id\n",
       "0    2025-11-01   63.0  Singapore       1666\n",
       "1    2025-11-02   47.0  Singapore       1666\n",
       "2    2025-11-03   50.0  Singapore       1666\n",
       "3    2025-11-04   71.0  Singapore       1666\n",
       "4    2025-11-05   68.0  Singapore       1666\n",
       "...         ...    ...        ...        ...\n",
       "3577 2016-03-28   65.0  Singapore       1666\n",
       "3578 2016-03-29  104.0  Singapore       1666\n",
       "3579 2016-03-30   94.0  Singapore       1666\n",
       "3580 2016-03-31  104.0  Singapore       1666\n",
       "3673 2016-01-01   23.0  Singapore       1666\n",
       "\n",
       "[3582 rows x 4 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aq.dropna(inplace=True)\n",
    "df_aq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c6dc05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3582 entries, 0 to 3673\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   date       3582 non-null   datetime64[ns]\n",
      " 1   pm25       3582 non-null   float32       \n",
      " 2   city       3582 non-null   object        \n",
      " 3   sensor_id  3582 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float32(1), int64(1), object(1)\n",
      "memory usage: 125.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_aq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055befa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Loading Weather Data from [Open Meteo](https://open-meteo.com/en/docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "96d604b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-01-01'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliest_aq_date = pd.Series.min(df_aq['date'])\n",
    "earliest_aq_date = earliest_aq_date.strftime('%Y-%m-%d')\n",
    "earliest_aq_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4f96fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "latitude = 1.3667\n",
    "longitude = 103.8\n",
    "\n",
    "params = {\n",
    "    \"latitude\": latitude,\n",
    "    \"longitude\": longitude,\n",
    "    \"start_date\": earliest_aq_date,\n",
    "    \"format\": \"json\",\n",
    "    \"end_date\": datetime.datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"daily\": [\"temperature_2m_mean\", \"precipitation_sum\", \"wind_speed_10m_max\", \"wind_direction_10m_dominant\"]\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Extract the JSON content from the response\n",
    "    data = response.json()\n",
    "else:\n",
    "    print(\"Failed to retrieve data. Status Code:\", response.status_code)\n",
    "    raise requests.exceptions.RequestException(response.status_code)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e93b2bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = data[\"daily\"]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"date\": pd.to_datetime(d[\"time\"]),\n",
    "    \"temperature_2m_mean\": d[\"temperature_2m_mean\"],\n",
    "    \"precipitation_sum\": d[\"precipitation_sum\"],\n",
    "    \"wind_speed_10m_max\": d[\"wind_speed_10m_max\"],\n",
    "    \"wind_direction_10m_dominant\": d[\"wind_direction_10m_dominant\"],\n",
    "})\n",
    "\n",
    "df[\"city\"] = \"Singapore\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bbfcdcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                           0\n",
      "temperature_2m_mean            0\n",
      "precipitation_sum              0\n",
      "wind_speed_10m_max             0\n",
      "wind_direction_10m_dominant    0\n",
      "city                           0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, temperature_2m_mean, precipitation_sum, wind_speed_10m_max, wind_direction_10m_dominant, city]\n",
       "Index: []"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many nulls exist per column\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Show only rows where ANY column has a null value\n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4d578a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd6eefe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3597 entries, 0 to 3596\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   date                         3597 non-null   datetime64[ns]\n",
      " 1   temperature_2m_mean          3597 non-null   float64       \n",
      " 2   precipitation_sum            3597 non-null   float64       \n",
      " 3   wind_speed_10m_max           3597 non-null   float64       \n",
      " 4   wind_direction_10m_dominant  3597 non-null   int64         \n",
      " 5   city                         3597 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(1)\n",
      "memory usage: 168.7+ KB\n"
     ]
    }
   ],
   "source": [
    "weather_df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d5eeb",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 10: Define Data Validation Rules </span>\n",
    "\n",
    "We will validate the air quality measurements (`pm25` values) before we write them to Hopsworks.\n",
    "\n",
    "We define a data validation rule (an expectation in Great Expectations) that ensures that `pm25` values are not negative or above the max value available by the sensor.\n",
    "\n",
    "We will attach this expectation to the air quality feature group, so that we validate the `pm25` data every time we write a DataFrame to the feature group. We want to prevent garbage-in, garbage-out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "11bcdcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"expectation_type\": \"expect_column_min_to_be_between\", \"kwargs\": {\"column\": \"pm25\", \"min_value\": -0.1, \"max_value\": 500.0, \"strict_min\": true}, \"meta\": {}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import great_expectations as ge\n",
    "\n",
    "\n",
    "aq_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"aq_expectation_suite\"\n",
    ")\n",
    "\n",
    "aq_expectation_suite.add_expectation(\n",
    "    ge.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_min_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":\"pm25\",\n",
    "            \"min_value\":-0.1,\n",
    "            \"max_value\":500.0,\n",
    "            \"strict_min\":True\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bef9ed3",
   "metadata": {},
   "source": [
    "## Expectations for Weather Data\n",
    "Here, we define an expectation for 2 columns in our weather DataFrame - `precipitation_sum` and `wind_speed_10m_max`, where we expect both values to be greater than zero, but less than 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0bff8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "weather_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"weather_expectation_suite\"\n",
    ")\n",
    "\n",
    "def expect_greater_than_zero(col):\n",
    "    weather_expectation_suite.add_expectation(\n",
    "        ge.core.ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_min_to_be_between\",\n",
    "            kwargs={\n",
    "                \"column\":col,\n",
    "                \"min_value\":-0.1,\n",
    "                \"max_value\":1000.0,\n",
    "                \"strict_min\":True\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "expect_greater_than_zero(\"precipitation_sum\")\n",
    "expect_greater_than_zero(\"wind_speed_10m_max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3830b7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291a502",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ STEP 11: Connect to Hopsworks and save the sensor country, city, street names as a secret</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aeaf20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd82f7",
   "metadata": {},
   "source": [
    "#### Save country, city, street names as a secret\n",
    "\n",
    "These will be downloaded from Hopsworks later in the (1) daily feature pipeline and (2) the daily batch inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cd36749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing existing SENSOR_LOCATION_JSON\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Secret('SENSOR_LOCATION_JSON', 'PRIVATE')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_obj = {\n",
    "    \"country\": \"Singapore\",\n",
    "    \"city\": \"Singapore\",\n",
    "    \"street\": \"Central\",\n",
    "    \"sensor_id\": sensor_id,\n",
    "    \"latitude\": latitude,\n",
    "    \"longitude\": longitude\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a JSON string\n",
    "str_dict = json.dumps(dict_obj)\n",
    "\n",
    "# Replace any existing secret with the new value\n",
    "secret = secrets.get_secret(\"SENSOR_LOCATION_JSON\")\n",
    "if secret is not None:\n",
    "    secret.delete()\n",
    "    print(\"Replacing existing SENSOR_LOCATION_JSON\")\n",
    "\n",
    "secrets.create_secret(\"SENSOR_LOCATION_JSON\", str_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e79b3f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ STEP 12: Create the Feature Groups and insert the DataFrames in them </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3755b6f",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üå´ Air Quality Data\n",
    "    \n",
    " 1. Provide a name, description, and version for the feature group.\n",
    " 2. Define the `primary_key`: we have to select which columns uniquely identify each row in the DataFrame - by providing them as the `primary_key`. Here, each air quality sensor measurement is uniquely identified by `country`, `street`, and  `date`.\n",
    " 3. Define the `event_time`: We also define which column stores the timestamp or date for the row - `date`.\n",
    " 4. Attach any `expectation_suite` containing data validation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4d2bb403",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "air_quality_fg = fs.get_or_create_feature_group(\n",
    "    name='air_quality',\n",
    "    description='Air Quality characteristics of each day',\n",
    "    version=1,\n",
    "    primary_key=['city', 'sensor_id'],\n",
    "    event_time=\"date\",\n",
    "    expectation_suite=aq_expectation_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2933cfa5",
   "metadata": {},
   "source": [
    "#### Insert the DataFrame into the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0fb42574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1279137/fs/1265747/fg/1596048\n",
      "2025-11-05 22:44:42,729 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279137/fs/1265747/fg/1596048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 3582/3582 | Elapsed Time: 00:02 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279137/jobs/named/air_quality_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('air_quality_1_offline_fg_materialization', 'SPARK'),\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pm25\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 500.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 733244\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 12.999999046325684,\n",
       "         \"element_count\": 3582,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-05T09:44:42.000727Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 1,\n",
       "     \"successful_expectations\": 1,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"aq_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2025-11-05T22:44:42.727937+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"a35bec04-ba90-11f0-aad8-96b98f3d793d\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20251105T214442.727711Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_quality_fg.insert(df_aq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a1606",
   "metadata": {},
   "source": [
    "#### Enter a description for each feature in the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "577effca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x304482cd0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_quality_fg.update_feature_description(\"date\", \"Date of measurement of air quality\")\n",
    "air_quality_fg.update_feature_description(\"city\", \"City where the air quality was measured\")\n",
    "air_quality_fg.update_feature_description(\"pm25\", \"Particles less than 2.5 micrometers in diameter (fine particles) pose health risk\")\n",
    "air_quality_fg.update_feature_description(\"sensor_id\", \"Sensor ID of the air quality measurement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894b731",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üå¶ Weather Data\n",
    "    \n",
    " 1. Provide a name, description, and version for the feature group.\n",
    " 2. Define the `primary_key`: we have to select which columns uniquely identify each row in the DataFrame - by providing them as the `primary_key`. Here, each weather measurement is uniquely identified by `city` and  `date`.\n",
    " 3. Define the `event_time`: We also define which column stores the timestamp or date for the row - `date`.\n",
    " 4. Attach any `expectation_suite` containing data validation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a84ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Get or create feature group \n",
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name='weather',\n",
    "    description='Weather characteristics of each day',\n",
    "    version=1,\n",
    "    primary_key=['city'],\n",
    "    event_time=\"date\",\n",
    "    expectation_suite=weather_expectation_suite\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721881b7",
   "metadata": {},
   "source": [
    "#### Insert the DataFrame into the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba846ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Insert data\n",
    "weather_fg.insert(weather_df, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87422d",
   "metadata": {},
   "source": [
    "#### Enter a description for each feature in the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e6f6d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "weather_fg.update_feature_description(\"date\", \"Date of measurement of weather\")\n",
    "weather_fg.update_feature_description(\"city\", \"City where weather is measured/forecast for\")\n",
    "weather_fg.update_feature_description(\"temperature_2m_mean\", \"Temperature in Celsius\")\n",
    "weather_fg.update_feature_description(\"precipitation_sum\", \"Precipitation (rain/snow) in mm\")\n",
    "weather_fg.update_feature_description(\"wind_speed_10m_max\", \"Wind speed at 10m abouve ground\")\n",
    "weather_fg.update_feature_description(\"wind_direction_10m_dominant\", \"Dominant Wind direction over the dayd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc16b5",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 02: Daily Feature Pipeline \n",
    " </span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c029117",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Exercises:** \n",
    " </span> \n",
    "\n",
    "Extra Homework:\n",
    "\n",
    "  * Try adding a new feature based on a rolling window of 3 days for 'pm25'\n",
    "      * This is not easy, as forecasting more than 1 day in the future, you won't have the previous 3 days of pm25 measurements.\n",
    "      * df.set_index(\"date\").rolling(3).mean() is only the start....\n",
    "  * Parameterize the notebook, so that you can provide the `country`/`street`/`city`/`url`/`csv_file` as parameters. \n",
    "      * Hint: this will also require making the secret name (`SENSOR_LOCATION_JSON`), e.g., add the street name as part of the secret name. Then you have to pass that secret name as a parameter when running the operational feature pipeline and batch inference pipelines.\n",
    "      * After you have done this, collect the street/city/url/csv files for all the sensors in your city or region and you make dashboards for all of the air quality sensors in your city/region. You could even then add a dashboard for your city/region, as done [here for Poland](https://github.com/erno98/ID2223).\n",
    "\n",
    "Improve this AI System\n",
    "  * As of mid 2024, there is no API call available to download historical data from the AQIN website. You could improve this system by writing a PR to download the CSV file using Python Selenium and the URL for the sensor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb407899",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
