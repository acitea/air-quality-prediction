{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e46aad",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">Part 02: Daily Feature Pipeline</span>\n",
    "\n",
    "Daily pipeline to fetch and store air quality and weather data for all sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de2e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99df28bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-06 01:30:41,489 INFO: Initializing external client\n",
      "2025-11-06 01:30:41,497 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-06 01:30:43,438 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279137\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login(engine=\"python\")\n",
    "fs = project.get_feature_store() \n",
    "secrets = hopsworks.get_secrets_api()\n",
    "\n",
    "# This line will fail if you have not registered the AQICN_API_KEY as a secret in Hopsworks\n",
    "AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "location_str = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "locations = json.loads(location_str)\n",
    "\n",
    "\n",
    "today = datetime.date.today()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7130c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "CITY = \"Singapore\"\n",
    "COUNTRY = \"Singapore\"\n",
    "LATITUDE = 1.3667\n",
    "LONGITUDE = 103.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "958721b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality',\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b70cd57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved PM2.5 for sensor 1666 (Central): 95.0\n",
      "Retrieved PM2.5 for sensor 1664 (East): 93.0\n",
      "Retrieved PM2.5 for sensor 1665 (West): 55.0\n",
      "Retrieved PM2.5 for sensor 1662 (North): 72.0\n",
      "Retrieved PM2.5 for sensor 1663 (South): 74.0\n",
      "\n",
      "Total sensors processed: 5\n"
     ]
    }
   ],
   "source": [
    "# Get air quality data for all sensors\n",
    "def get_pm25(sensor_id, city, date, api_key):\n",
    "    url = f\"https://api.waqi.info/feed/@{sensor_id}/?token={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise requests.exceptions.RequestException(f\"Failed to retrieve data. Status Code: {response.status_code}\")\n",
    "    \n",
    "    data = response.json()\n",
    "    if data['status'] != 'ok':\n",
    "        raise Exception(f\"Error: {data['status']}\")\n",
    "    \n",
    "    aqi_data = data['data']\n",
    "    pm25_value = aqi_data['iaqi'].get('pm25', {}).get('v', None)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'date': [pd.to_datetime(date)],\n",
    "        'pm25': [float(pm25_value) if pm25_value is not None else None],\n",
    "        'city': [city],\n",
    "        'sensor_id': [sensor_id]\n",
    "    })\n",
    "\n",
    "all_aq_data = []\n",
    "for location in locations:\n",
    "    sensor_id = location['sensor_id']\n",
    "    city = location['city']\n",
    "    df_aq = get_pm25(sensor_id, city, today, AQICN_API_KEY)\n",
    "    all_aq_data.append(df_aq)\n",
    "    print(f\"Retrieved PM2.5 for sensor {sensor_id} ({location['street']}): {df_aq['pm25'].iloc[0]}\")\n",
    "\n",
    "aq_today_df = pd.concat(all_aq_data, ignore_index=True)\n",
    "aq_today_df['pm25'] = aq_today_df['pm25'].astype('float32')\n",
    "print(f\"\\nTotal sensors processed: {len(all_aq_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66f5d7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-06 01:31:53,311 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279137/fs/1265747/fg/1596048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 5/5 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279137/jobs/named/air_quality_1_offline_fg_materialization/executions\n",
      "Air quality data inserted successfully\n"
     ]
    }
   ],
   "source": [
    "# Insert air quality data for all sensors\n",
    "air_quality_fg.insert(aq_today_df)\n",
    "print(\"Air quality data inserted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f681af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latitude': 1.5, 'longitude': 103.5, 'generationtime_ms': 0.05984306335449219, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 39.0, 'hourly_units': {'time': 'iso8601', 'temperature_2m': '°C', 'precipitation': 'mm', 'wind_speed_10m': 'km/h', 'wind_direction_10m': '°'}, 'hourly': {'time': ['2025-11-06T00:00', '2025-11-06T01:00', '2025-11-06T02:00', '2025-11-06T03:00', '2025-11-06T04:00', '2025-11-06T05:00', '2025-11-06T06:00', '2025-11-06T07:00', '2025-11-06T08:00', '2025-11-06T09:00', '2025-11-06T10:00', '2025-11-06T11:00', '2025-11-06T12:00', '2025-11-06T13:00', '2025-11-06T14:00', '2025-11-06T15:00', '2025-11-06T16:00', '2025-11-06T17:00', '2025-11-06T18:00', '2025-11-06T19:00', '2025-11-06T20:00', '2025-11-06T21:00', '2025-11-06T22:00', '2025-11-06T23:00', '2025-11-07T00:00', '2025-11-07T01:00', '2025-11-07T02:00', '2025-11-07T03:00', '2025-11-07T04:00', '2025-11-07T05:00', '2025-11-07T06:00', '2025-11-07T07:00', '2025-11-07T08:00', '2025-11-07T09:00', '2025-11-07T10:00', '2025-11-07T11:00', '2025-11-07T12:00', '2025-11-07T13:00', '2025-11-07T14:00', '2025-11-07T15:00', '2025-11-07T16:00', '2025-11-07T17:00', '2025-11-07T18:00', '2025-11-07T19:00', '2025-11-07T20:00', '2025-11-07T21:00', '2025-11-07T22:00', '2025-11-07T23:00', '2025-11-08T00:00', '2025-11-08T01:00', '2025-11-08T02:00', '2025-11-08T03:00', '2025-11-08T04:00', '2025-11-08T05:00', '2025-11-08T06:00', '2025-11-08T07:00', '2025-11-08T08:00', '2025-11-08T09:00', '2025-11-08T10:00', '2025-11-08T11:00', '2025-11-08T12:00', '2025-11-08T13:00', '2025-11-08T14:00', '2025-11-08T15:00', '2025-11-08T16:00', '2025-11-08T17:00', '2025-11-08T18:00', '2025-11-08T19:00', '2025-11-08T20:00', '2025-11-08T21:00', '2025-11-08T22:00', '2025-11-08T23:00', '2025-11-09T00:00', '2025-11-09T01:00', '2025-11-09T02:00', '2025-11-09T03:00', '2025-11-09T04:00', '2025-11-09T05:00', '2025-11-09T06:00', '2025-11-09T07:00', '2025-11-09T08:00', '2025-11-09T09:00', '2025-11-09T10:00', '2025-11-09T11:00', '2025-11-09T12:00', '2025-11-09T13:00', '2025-11-09T14:00', '2025-11-09T15:00', '2025-11-09T16:00', '2025-11-09T17:00', '2025-11-09T18:00', '2025-11-09T19:00', '2025-11-09T20:00', '2025-11-09T21:00', '2025-11-09T22:00', '2025-11-09T23:00', '2025-11-10T00:00', '2025-11-10T01:00', '2025-11-10T02:00', '2025-11-10T03:00', '2025-11-10T04:00', '2025-11-10T05:00', '2025-11-10T06:00', '2025-11-10T07:00', '2025-11-10T08:00', '2025-11-10T09:00', '2025-11-10T10:00', '2025-11-10T11:00', '2025-11-10T12:00', '2025-11-10T13:00', '2025-11-10T14:00', '2025-11-10T15:00', '2025-11-10T16:00', '2025-11-10T17:00', '2025-11-10T18:00', '2025-11-10T19:00', '2025-11-10T20:00', '2025-11-10T21:00', '2025-11-10T22:00', '2025-11-10T23:00', '2025-11-11T00:00', '2025-11-11T01:00', '2025-11-11T02:00', '2025-11-11T03:00', '2025-11-11T04:00', '2025-11-11T05:00', '2025-11-11T06:00', '2025-11-11T07:00', '2025-11-11T08:00', '2025-11-11T09:00', '2025-11-11T10:00', '2025-11-11T11:00', '2025-11-11T12:00', '2025-11-11T13:00', '2025-11-11T14:00', '2025-11-11T15:00', '2025-11-11T16:00', '2025-11-11T17:00', '2025-11-11T18:00', '2025-11-11T19:00', '2025-11-11T20:00', '2025-11-11T21:00', '2025-11-11T22:00', '2025-11-11T23:00', '2025-11-12T00:00', '2025-11-12T01:00', '2025-11-12T02:00', '2025-11-12T03:00', '2025-11-12T04:00', '2025-11-12T05:00', '2025-11-12T06:00', '2025-11-12T07:00', '2025-11-12T08:00', '2025-11-12T09:00', '2025-11-12T10:00', '2025-11-12T11:00', '2025-11-12T12:00', '2025-11-12T13:00', '2025-11-12T14:00', '2025-11-12T15:00', '2025-11-12T16:00', '2025-11-12T17:00', '2025-11-12T18:00', '2025-11-12T19:00', '2025-11-12T20:00', '2025-11-12T21:00', '2025-11-12T22:00', '2025-11-12T23:00'], 'temperature_2m': [26.5, 27.8, 29.2, 30.2, 30.7, 30.9, 30.9, 30.9, 30.8, 30.2, 29.1, 27.7, 26.5, 26.0, 25.9, 25.6, 25.3, 25.0, 24.7, 24.5, 24.5, 24.6, 24.9, 25.4, 26.1, 27.3, 28.8, 29.9, 30.6, 31.0, 31.1, 31.0, 30.6, 30.0, 29.0, 27.7, 26.6, 26.1, 25.8, 25.5, 25.5, 25.7, 25.5, 24.8, 23.9, 23.3, 23.6, 24.4, 25.4, 26.9, 28.6, 30.0, 30.6, 30.8, 30.8, 30.9, 30.8, 30.3, 29.2, 27.8, 26.5, 26.0, 25.6, 25.2, 24.8, 24.3, 23.9, 23.5, 23.2, 23.1, 23.1, 23.2, 23.8, 25.1, 26.9, 28.4, 29.3, 29.9, 30.3, 30.5, 30.5, 30.1, 29.3, 28.0, 26.8, 25.5, 24.3, 23.4, 23.2, 23.3, 23.4, 23.3, 23.1, 23.0, 23.1, 23.3, 23.8, 25.0, 26.5, 27.8, 28.8, 29.6, 30.0, 30.0, 29.7, 29.0, 27.6, 26.0, 24.6, 24.0, 23.9, 23.6, 23.5, 23.4, 23.4, 23.4, 23.4, 23.5, 23.9, 24.4, 25.1, 26.1, 27.4, 28.4, 29.0, 29.4, 29.5, 29.6, 29.5, 29.0, 27.8, 26.3, 25.0, 24.5, 24.2, 24.0, 23.8, 23.7, 23.6, 23.5, 23.5, 23.5, 23.6, 23.8, 24.2, 25.1, 26.3, 27.4, 28.4, 29.4, 29.9, 29.6, 28.9, 28.0, 27.2, 26.2, 25.4, 25.0, 24.6, 24.4, 24.2, 24.1, 24.0, 23.9, 23.7, 23.6, 23.8, 24.0], 'precipitation': [0.0, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.0, 0.0, 0.0, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.6, 0.6, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.5, 1.5, 1.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1, 3.1, 3.1, 0.2, 0.2, 0.2, 4.0, 4.0, 4.0, 0.2, 0.2, 0.2, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 0.3, 0.3, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.4, 0.4, 0.4, 0.3, 0.3, 0.3, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.1], 'wind_speed_10m': [2.6, 5.7, 10.7, 13.9, 14.6, 13.8, 13.1, 12.3, 11.2, 9.7, 7.3, 4.9, 3.5, 2.5, 1.0, 0.4, 3.0, 8.0, 10.2, 7.2, 1.8, 1.8, 1.1, 1.6, 4.6, 7.9, 11.7, 14.7, 15.3, 14.9, 13.7, 12.3, 10.5, 8.3, 5.8, 3.3, 1.8, 1.5, 1.8, 2.2, 2.2, 1.8, 1.1, 1.3, 3.9, 5.3, 4.5, 2.9, 1.4, 2.9, 5.8, 8.3, 10.3, 12.0, 12.6, 11.9, 10.5, 8.4, 5.5, 2.3, 0.5, 1.8, 2.6, 3.0, 2.3, 3.4, 4.0, 3.6, 5.9, 8.4, 8.2, 6.8, 6.2, 7.1, 8.8, 10.8, 12.6, 14.5, 15.4, 14.8, 13.0, 10.8, 7.2, 3.6, 3.6, 5.1, 5.8, 6.1, 4.3, 2.1, 1.3, 2.9, 6.6, 9.3, 9.3, 7.8, 6.8, 6.5, 7.4, 9.2, 11.4, 14.1, 15.8, 16.5, 16.1, 14.3, 9.6, 4.7, 4.8, 5.2, 4.2, 3.6, 3.6, 3.6, 4.0, 5.2, 7.4, 8.7, 7.1, 5.4, 4.9, 4.3, 7.9, 11.9, 13.6, 13.8, 13.1, 11.5, 9.5, 7.9, 6.8, 6.2, 6.3, 6.3, 5.8, 5.2, 4.6, 3.6, 3.1, 2.9, 3.4, 3.4, 3.1, 2.8, 2.1, 1.8, 4.4, 6.8, 9.4, 11.5, 12.3, 10.8, 8.0, 4.9, 2.9, 3.9, 6.1, 6.9, 7.0, 6.8, 6.7, 6.8, 6.8, 6.5, 6.1, 5.8, 5.1, 4.3], 'wind_direction_10m': [236, 252, 256, 260, 260, 261, 262, 265, 268, 272, 281, 306, 336, 360, 45, 90, 284, 288, 288, 288, 270, 127, 108, 297, 288, 273, 261, 259, 261, 263, 265, 267, 266, 268, 270, 283, 307, 346, 360, 9, 9, 11, 18, 124, 146, 152, 151, 150, 180, 240, 248, 252, 258, 263, 267, 270, 276, 280, 281, 288, 45, 53, 34, 14, 342, 288, 280, 323, 11, 20, 15, 360, 339, 319, 305, 296, 290, 284, 281, 276, 270, 266, 273, 307, 360, 8, 4, 360, 5, 31, 56, 7, 351, 347, 347, 347, 342, 326, 309, 296, 288, 283, 282, 280, 280, 282, 290, 328, 27, 34, 20, 6, 6, 6, 355, 335, 321, 318, 330, 360, 17, 336, 294, 284, 281, 279, 279, 284, 295, 309, 328, 353, 13, 24, 30, 34, 39, 45, 54, 60, 58, 58, 54, 50, 31, 323, 279, 273, 270, 266, 267, 268, 275, 287, 330, 34, 45, 43, 35, 25, 16, 3, 357, 357, 360, 4, 4, 360]}}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.open-meteo.com/v1/ecmwf\"\n",
    "\n",
    "params = {\n",
    "    \"latitude\": LATITUDE,\n",
    "    \"longitude\": LONGITUDE,\n",
    "    \"format\": \"json\",\n",
    "    \"hourly\": [\"temperature_2m\", \"precipitation\", \"wind_speed_10m\", \"wind_direction_10m\"]\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "if response.status_code != 200:\n",
    "    raise requests.exceptions.RequestException(f\"Failed to retrieve weather data. Status Code: {response.status_code}\")\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "\n",
    "print(data)\n",
    "\n",
    "\n",
    "\n",
    "hourly = data[\"hourly\"]\n",
    "hourly_df = pd.DataFrame({\n",
    "    \"time\": pd.to_datetime(hourly[\"time\"]),\n",
    "    \"temperature_2m\": hourly[\"temperature_2m\"],\n",
    "    \"precipitation\": hourly[\"precipitation\"],\n",
    "    \"wind_speed_10m\": hourly[\"wind_speed_10m\"],\n",
    "    \"wind_direction_10m\": hourly[\"wind_direction_10m\"]\n",
    "})\n",
    "\n",
    "hourly_df = hourly_df.set_index('time')\n",
    "\n",
    "mean_temp = hourly_df[\"temperature_2m\"].mean()\n",
    "precipitation_sum = hourly_df[\"precipitation\"].sum()\n",
    "max_wind_speed = hourly_df[\"wind_speed_10m\"].max()\n",
    "dominant_wind_direction = hourly_df[\"wind_direction_10m\"].mode()[0] if not hourly_df[\"wind_direction_10m\"].mode().empty else np.nan\n",
    "\n",
    "daily_weather_df = pd.DataFrame({\n",
    "    \"date\": [datetime.datetime.now().strftime(\"%Y-%m-%d\")],\n",
    "    \"temperature_2m_mean\": [mean_temp],\n",
    "    \"precipitation_sum\": [precipitation_sum],\n",
    "    \"wind_speed_10m_max\": [max_wind_speed],\n",
    "    \"wind_direction_10m_dominant\": [dominant_wind_direction],\n",
    "    \"city\": [CITY]\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "077876e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-06</td>\n",
       "      <td>26.475</td>\n",
       "      <td>52.1</td>\n",
       "      <td>16.5</td>\n",
       "      <td>360</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  temperature_2m_mean  precipitation_sum  wind_speed_10m_max  \\\n",
       "0  2025-11-06               26.475               52.1                16.5   \n",
       "\n",
       "   wind_direction_10m_dominant       city  \n",
       "0                          360  Singapore  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b41c2d74",
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureStoreException",
     "evalue": "Features are not compatible with Feature Group schema: \n - date (expected type: 'timestamp', derived from input: 'date') has the wrong type.\nNote that feature (or column) names are case insensitive and spaces are automatically replaced with underscores.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFeatureStoreException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mweather_fg\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdaily_weather_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/air-quality-prediction/.venv/lib/python3.11/site-packages/hsfs/feature_group.py:3153\u001b[39m, in \u001b[36mFeatureGroup.insert\u001b[39m\u001b[34m(self, features, overwrite, operation, storage, write_options, validation_options, wait, transformation_context, transform)\u001b[39m\n\u001b[32m   3150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._id \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._offline_backfill_every_hr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3151\u001b[39m     write_options[\u001b[33m\"\u001b[39m\u001b[33moffline_backfill_every_hr\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._offline_backfill_every_hr\n\u001b[32m-> \u001b[39m\u001b[32m3153\u001b[39m job, ge_report = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_feature_group_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3154\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3156\u001b[39m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3157\u001b[39m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m=\u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   3159\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msave_report\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mvalidation_options\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformation_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3162\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3163\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine.get_type().startswith(\u001b[33m\"\u001b[39m\u001b[33mspark\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream:\n\u001b[32m   3166\u001b[39m     \u001b[38;5;66;03m# Also, only compute statistics if stream is False.\u001b[39;00m\n\u001b[32m   3167\u001b[39m     \u001b[38;5;66;03m# if True, the backfill job has not been triggered and the data has not been inserted (it's in Kafka)\u001b[39;00m\n\u001b[32m   3168\u001b[39m     \u001b[38;5;28mself\u001b[39m.compute_statistics()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/air-quality-prediction/.venv/lib/python3.11/site-packages/hsfs/core/feature_group_engine.py:209\u001b[39m, in \u001b[36mFeatureGroupEngine.insert\u001b[39m\u001b[34m(self, feature_group, feature_dataframe, overwrite, operation, storage, write_options, validation_options, transformation_context, transform)\u001b[39m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28mself\u001b[39m.save_feature_group_metadata(\n\u001b[32m    205\u001b[39m         feature_group, dataframe_features, write_options\n\u001b[32m    206\u001b[39m     )\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    208\u001b[39m     \u001b[38;5;66;03m# else, just verify that feature group schema matches user-provided dataframe\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_verify_schema_compatibility\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframe_features\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[38;5;66;03m# ge validation on python and non stream feature groups on spark\u001b[39;00m\n\u001b[32m    214\u001b[39m ge_report = feature_group._great_expectation_engine.validate(\n\u001b[32m    215\u001b[39m     feature_group=feature_group,\n\u001b[32m    216\u001b[39m     dataframe=feature_dataframe,\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m     ge_type=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    220\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/air-quality-prediction/.venv/lib/python3.11/site-packages/hsfs/core/feature_group_base_engine.py:186\u001b[39m, in \u001b[36mFeatureGroupBaseEngine._verify_schema_compatibility\u001b[39m\u001b[34m(self, feature_group_features, dataframe_features)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# raise exception if any errors were found.\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(err) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m FeatureStoreException(\n\u001b[32m    187\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFeatures are not compatible with Feature Group schema: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    188\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m - \u001b[39m\u001b[33m\"\u001b[39m + e \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m err])\n\u001b[32m    189\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mNote that feature (or column) names are case insensitive and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    190\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mspaces are automatically replaced with underscores.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    191\u001b[39m     )\n",
      "\u001b[31mFeatureStoreException\u001b[39m: Features are not compatible with Feature Group schema: \n - date (expected type: 'timestamp', derived from input: 'date') has the wrong type.\nNote that feature (or column) names are case insensitive and spaces are automatically replaced with underscores."
     ]
    }
   ],
   "source": [
    "weather_fg.insert(daily_weather_df, wait=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
