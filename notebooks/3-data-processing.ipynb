{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f314f9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e54b6cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "333ce09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory based on root folder\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "\n",
    "# GET ABSOLUTE PATH\n",
    "head, _ = os.path.split(os.getcwd()) # Get parent directory, from notebooks\n",
    "DATA_DIR = os.path.join(head, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b71625",
   "metadata": {},
   "source": [
    "# DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "151920ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename: str, prefix: str=\"\", data_dir: os.PathLike=DATA_DIR):\n",
    "    \"\"\"Load data file with a specific prefix\"\"\"\n",
    "\n",
    "    filename = f\"{prefix}-{filename}\" if len(prefix) else filename\n",
    "\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"Data file not found: {filepath}. Run scraping first.\")\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    # if 'date' in df.columns:\n",
    "    #     df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# ============================================================================\n",
    "# DATA LOADING FUNCTIONS WINDSPEED AND DIRECTION\n",
    "# ============================================================================\n",
    "\n",
    "def load_all_stations(input_dir: os.PathLike =DATA_DIR, file_pattern: str=\"\"):\n",
    "    \"\"\"Load data for all stations\"\"\"\n",
    "    import glob\n",
    "    pattern = os.path.join(input_dir, file_pattern)\n",
    "    station_files = glob.glob(pattern)\n",
    "\n",
    "    station_dfs = []\n",
    "    for filepath in station_files:\n",
    "        filename = os.path.basename(filepath)\n",
    "        station_dfs.append(load_data(filename, data_dir=input_dir))\n",
    "\n",
    "    return pd.concat(station_dfs).reset_index(drop=True)\n",
    "\n",
    "def load_stations_metadata(input_dir: os.PathLike=DATA_DIR):\n",
    "    \"\"\"Load stations metadata\"\"\"\n",
    "    filename = os.path.join(input_dir, \"stations_metadata.csv\")\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(f\"Metadata file not found: {filename}\")\n",
    "\n",
    "    return pd.read_csv(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f38dcb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONS_PREFIX = ['east', 'west', 'north', 'south', 'central']\n",
    "\n",
    "pm25_hourly_df_temp = {region: load_data(f\"pm2.5-hourly-230701-251101.csv\", prefix=region, data_dir=os.path.join(DATA_DIR, \"pm2.5-hourly\")) for region in REGIONS_PREFIX}\n",
    "pm25_hourly_df = []\n",
    "for region, df in pm25_hourly_df_temp.items():\n",
    "    df['region'] = region\n",
    "    pm25_hourly_df.append(df)\n",
    "pm25_hourly_df = pd.concat(pm25_hourly_df).reset_index(drop=True)\n",
    "pm25_hourly_df['region'] = pm25_hourly_df['region'].astype('category')\n",
    "pm25_hourly_df['pm25'] = pd.to_numeric(pm25_hourly_df['pm25'], errors='coerce')\n",
    "pm25_hourly_df.drop(columns=['date'], axis=1, inplace=True)\n",
    "del pm25_hourly_df_temp\n",
    "\n",
    "\n",
    "pm25_daily_df_temp = {region: load_data(f\"singapore-air-quality.csv\", prefix=region, data_dir=os.path.join(DATA_DIR, \"pm2.5-daily\")) for region in REGIONS_PREFIX}\n",
    "pm25_daily_df = []\n",
    "for region, df in pm25_daily_df_temp.items():\n",
    "    df['region'] = region\n",
    "    pm25_daily_df.append(df)\n",
    "pm25_daily_df = pd.concat(pm25_daily_df).reset_index(drop=True)\n",
    "pm25_daily_df['region'] = pm25_daily_df['region'].astype('category')\n",
    "pm25_daily_df.drop(columns=['pm10', 'o3', 'no2', 'so2', 'co', 'psi'], axis=1, inplace=True)\n",
    "pm25_daily_df['pm25'] = pd.to_numeric(pm25_daily_df['pm25'], errors='coerce')\n",
    "del pm25_daily_df_temp\n",
    "\n",
    "\n",
    "wind_speed_df = load_all_stations(os.path.join(DATA_DIR, 'wind-speed'), file_pattern=\"*-wind-speed-hourly-*.csv\")\n",
    "wind_speed_df.drop(columns=['last_update'], axis=1, inplace=True)\n",
    "wind_speed_df['station_name'] = wind_speed_df['station_name'].astype('category')\n",
    "\n",
    "wind_direction_df = load_all_stations(os.path.join(DATA_DIR, 'wind-direction'), file_pattern=\"*-wind-direction-hourly-*.csv\")\n",
    "wind_direction_df.drop(columns=['last_update'], axis=1, inplace=True)\n",
    "wind_direction_df['station_name'] = wind_direction_df['station_name'].astype('category')\n",
    "\n",
    "air_temperature_df = load_all_stations(os.path.join(DATA_DIR, 'air-temperature'), file_pattern=\"*-air-temperature-hourly-*.csv\")\n",
    "air_temperature_df.drop(columns=['last_update'], axis=1, inplace=True)\n",
    "air_temperature_df['station_name'] = air_temperature_df['station_name'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dcf6bdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>station_name</th>\n",
       "      <th>air_temperature_avg</th>\n",
       "      <th>reading_count</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:00:00+08:00</td>\n",
       "      <td>Old Choa Chu Kang Road</td>\n",
       "      <td>25.961667</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.37288</td>\n",
       "      <td>103.72244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 01:00:00+08:00</td>\n",
       "      <td>Old Choa Chu Kang Road</td>\n",
       "      <td>25.696667</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.37288</td>\n",
       "      <td>103.72244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 02:00:00+08:00</td>\n",
       "      <td>Old Choa Chu Kang Road</td>\n",
       "      <td>25.528333</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.37288</td>\n",
       "      <td>103.72244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 03:00:00+08:00</td>\n",
       "      <td>Old Choa Chu Kang Road</td>\n",
       "      <td>25.128333</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.37288</td>\n",
       "      <td>103.72244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 04:00:00+08:00</td>\n",
       "      <td>Old Choa Chu Kang Road</td>\n",
       "      <td>25.216667</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.37288</td>\n",
       "      <td>103.72244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>2023-09-24 03:00:00+08:00</td>\n",
       "      <td>Old Choa Chu Kang Road</td>\n",
       "      <td>26.410000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.37288</td>\n",
       "      <td>103.72244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>2023-09-24 04:00:00+08:00</td>\n",
       "      <td>Old Choa Chu Kang Road</td>\n",
       "      <td>26.251667</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.37288</td>\n",
       "      <td>103.72244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>2023-09-24 05:00:00+08:00</td>\n",
       "      <td>Old Choa Chu Kang Road</td>\n",
       "      <td>26.160000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.37288</td>\n",
       "      <td>103.72244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>2023-09-24 06:00:00+08:00</td>\n",
       "      <td>Old Choa Chu Kang Road</td>\n",
       "      <td>26.161667</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.37288</td>\n",
       "      <td>103.72244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>2023-09-24 07:00:00+08:00</td>\n",
       "      <td>Old Choa Chu Kang Road</td>\n",
       "      <td>26.030000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.37288</td>\n",
       "      <td>103.72244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     timestamp            station_name  air_temperature_avg  \\\n",
       "0    2023-01-01 00:00:00+08:00  Old Choa Chu Kang Road            25.961667   \n",
       "1    2023-01-01 01:00:00+08:00  Old Choa Chu Kang Road            25.696667   \n",
       "2    2023-01-01 02:00:00+08:00  Old Choa Chu Kang Road            25.528333   \n",
       "3    2023-01-01 03:00:00+08:00  Old Choa Chu Kang Road            25.128333   \n",
       "4    2023-01-01 04:00:00+08:00  Old Choa Chu Kang Road            25.216667   \n",
       "...                        ...                     ...                  ...   \n",
       "5995 2023-09-24 03:00:00+08:00  Old Choa Chu Kang Road            26.410000   \n",
       "5996 2023-09-24 04:00:00+08:00  Old Choa Chu Kang Road            26.251667   \n",
       "5997 2023-09-24 05:00:00+08:00  Old Choa Chu Kang Road            26.160000   \n",
       "5998 2023-09-24 06:00:00+08:00  Old Choa Chu Kang Road            26.161667   \n",
       "5999 2023-09-24 07:00:00+08:00  Old Choa Chu Kang Road            26.030000   \n",
       "\n",
       "      reading_count  latitude  longitude  \n",
       "0              60.0   1.37288  103.72244  \n",
       "1              60.0   1.37288  103.72244  \n",
       "2              60.0   1.37288  103.72244  \n",
       "3              60.0   1.37288  103.72244  \n",
       "4              60.0   1.37288  103.72244  \n",
       "...             ...       ...        ...  \n",
       "5995           60.0   1.37288  103.72244  \n",
       "5996           60.0   1.37288  103.72244  \n",
       "5997           60.0   1.37288  103.72244  \n",
       "5998           60.0   1.37288  103.72244  \n",
       "5999           60.0   1.37288  103.72244  \n",
       "\n",
       "[6000 rows x 6 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLAYGROUND AREA TO VIEW LOADED DATAFRAMES\n",
    "\n",
    "air_temperature_df.head(6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d89585bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pm25</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-01 00:00:00+08:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-01 01:00:00+08:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-01 02:00:00+08:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-01 03:00:00+08:00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-01 04:00:00+08:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp  pm25 region\n",
       "0 2023-07-01 00:00:00+08:00  13.0   east\n",
       "1 2023-07-01 01:00:00+08:00  14.0   east\n",
       "2 2023-07-01 02:00:00+08:00  11.0   east\n",
       "3 2023-07-01 03:00:00+08:00  16.0   east\n",
       "4 2023-07-01 04:00:00+08:00   7.0   east"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm25_hourly_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a6339d",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING FOR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "666745ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION_COORDS = pd.DataFrame({\n",
    "    \"region\": [\"central\", \"north\", \"south\", \"east\", \"west\"],\n",
    "    \"latitude\": [1.3521, 1.4180, 1.2800, 1.3500, 1.3400],\n",
    "    \"longitude\": [103.8198, 103.8270, 103.8500, 103.9400, 103.7000]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab15879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2522a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "def regression_features_pm25_daily(df: pd.DataFrame):\n",
    "    \"\"\"Prepare features for time series regression modeling\"\"\"\n",
    "    df = df.copy().sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "    # Time-based features\n",
    "    df['day_of_week'] = (df['timestamp'].dt.dayofweek).astype('int8')\n",
    "    df['day_of_month'] = (df['timestamp'].dt.day).astype('int8')\n",
    "    df['month'] = (df['timestamp'].dt.month).astype('int8')\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    df['date'] = df['timestamp'].dt.date.astype('category')\n",
    "\n",
    "    # Lag features\n",
    "    for lag in [1, 2, 3, 4, 5, 6, 7, 14, 28]:\n",
    "        df[f'pm25_lag_{lag}d'] = df['pm25'].shift(lag)\n",
    "\n",
    "    # Rolling statistics\n",
    "    for window in [3, 7, 14, 28]:\n",
    "        min_valid = max(1, window // 2)\n",
    "        df[f'pm25_rolling_mean_{window}d'] = df['pm25'].shift(1).rolling(window, min_periods=min_valid).mean()\n",
    "        df[f'pm25_rolling_std_{window}d'] = df['pm25'].shift(1).rolling(window, min_periods=min_valid).std()\n",
    "        df[f'pm25_rolling_min_{window}d'] = df['pm25'].shift(1).rolling(window, min_periods=min_valid).min()\n",
    "        df[f'pm25_rolling_max_{window}d'] = df['pm25'].shift(1).rolling(window, min_periods=min_valid).max()\n",
    "\n",
    "    df_clean = df.dropna()\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def regression_features_pm25_hourly(df: pd.DataFrame):\n",
    "    \"\"\"Prepare features for time series regression modeling\"\"\"\n",
    "    df = df.copy().sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "    # Time-based features\n",
    "    df['hour'] = (df['timestamp'].dt.hour).astype('int8')\n",
    "    df['day_of_week'] = (df['timestamp'].dt.dayofweek).astype('int8')\n",
    "    df['day_of_month'] = (df['timestamp'].dt.day).astype('int8')\n",
    "    df['month'] = (df['timestamp'].dt.month).astype('int8')\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(bool)\n",
    "\n",
    "    # Lag features\n",
    "    for lag in [1, 2, 3, 6, 12, 24]:\n",
    "        df[f'pm25_lag_{lag}h'] = df['pm25'].shift(lag)\n",
    "\n",
    "    # Rolling statistics\n",
    "    for window in [6, 12, 24, 72, 168]:\n",
    "        min_valid = max(1, window // 2)\n",
    "        df[f'pm25_rolling_mean_{window}h'] = df['pm25'].shift(1).rolling(window, min_periods=min_valid).mean()\n",
    "        df[f'pm25_rolling_std_{window}h'] = df['pm25'].shift(1).rolling(window, min_periods=min_valid).std()\n",
    "        df[f'pm25_rolling_min_{window}h'] = df['pm25'].shift(1).rolling(window, min_periods=min_valid).min()\n",
    "        df[f'pm25_rolling_max_{window}h'] = df['pm25'].shift(1).rolling(window, min_periods=min_valid).max()\n",
    "\n",
    "    df_clean = df.dropna()\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def regression_features_wind_direction(df: pd.DataFrame):\n",
    "    \"\"\"Prepare features for time series regression modeling\"\"\"\n",
    "    df = df.copy().sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "    # Map coordinates to a sensor region\n",
    "    df[\"region\"] = _map_coords_to_region(df, REGION_COORDS)\n",
    "\n",
    "    # Time-based features\n",
    "    df['hour'] = (df['timestamp'].dt.hour).astype('int8')\n",
    "    df['day_of_week'] = (df['timestamp'].dt.dayofweek).astype('int8')\n",
    "    df['day_of_month'] = (df['timestamp'].dt.day).astype('int8')\n",
    "    df['month'] = (df['timestamp'].dt.month).astype('int8')\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(bool)\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "\n",
    "    # Convert direction to vector components (recommended for modeling)\n",
    "    df['wind_u'] = -np.sin(np.deg2rad(df['wind_direction_avg']))\n",
    "    df['wind_v'] = -np.cos(np.deg2rad(df['wind_direction_avg']))\n",
    "\n",
    "    # Lag features (using vector components)\n",
    "    for lag in [1, 2, 3, 6, 12, 24, 48, 72, 168]:\n",
    "        df[f'wind_u_lag_{lag}h'] = df['wind_u'].shift(lag)\n",
    "        df[f'wind_v_lag_{lag}h'] = df['wind_v'].shift(lag)\n",
    "        df[f'wind_direction_lag_{lag}h'] = df['wind_direction_avg'].shift(lag)\n",
    "\n",
    "    # Rolling statistics\n",
    "    for window in [6, 12, 24, 72, 168]:\n",
    "        min_valid = max(1, window // 2)\n",
    "        df[f'wind_u_rolling_mean_{window}h'] = df['wind_u'].shift(1).rolling(window, min_periods=min_valid).mean()\n",
    "        df[f'wind_v_rolling_mean_{window}h'] = df['wind_v'].shift(1).rolling(window, min_periods=min_valid).mean()\n",
    "        df[f'direction_std_rolling_mean_{window}h'] = df['wind_direction_std'].shift(1).rolling(window, min_periods=min_valid).mean()\n",
    "\n",
    "    df_clean = df.dropna()\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def regression_features_wind_speed(df: pd.DataFrame):\n",
    "    \"\"\"Prepare features for time series regression modeling\"\"\"\n",
    "    df = df.copy().sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "    # Map coordinates to a sensor region\n",
    "    df[\"region\"] = _map_coords_to_region(df, REGION_COORDS)\n",
    "\n",
    "    # Time-based features\n",
    "    df['hour'] = (df['timestamp'].dt.hour).astype('int8')\n",
    "    df['day_of_week'] = (df['timestamp'].dt.dayofweek).astype('int8')\n",
    "    df['day_of_month'] = (df['timestamp'].dt.day).astype('int8')\n",
    "    df['month'] = (df['timestamp'].dt.month).astype('int8')\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(bool)\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "\n",
    "    # Lag features\n",
    "    for lag in [1, 2, 3, 6, 12, 24, 48, 72, 168]:\n",
    "        df[f'wind_speed_lag_{lag}h'] = df['wind_speed_avg'].shift(lag)\n",
    "\n",
    "    # Rolling statistics\n",
    "    for window in [6, 12, 24, 72, 168]:\n",
    "        min_valid = max(1, window // 2)\n",
    "        df[f'wind_speed_rolling_mean_{window}h'] = df['wind_speed_avg'].shift(1).rolling(window, min_periods=min_valid).mean()\n",
    "        df[f'wind_speed_rolling_std_{window}h'] = df['wind_speed_avg'].shift(1).rolling(window, min_periods=min_valid).std()\n",
    "        df[f'wind_speed_rolling_min_{window}h'] = df['wind_speed_avg'].shift(1).rolling(window, min_periods=min_valid).min()\n",
    "        df[f'wind_speed_rolling_max_{window}h'] = df['wind_speed_avg'].shift(1).rolling(window, min_periods=min_valid).max()\n",
    "\n",
    "    df_clean = df.dropna()\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def regression_features_air_temperature(df: pd.DataFrame):\n",
    "    \"\"\"Prepare features for time series regression modeling\"\"\"\n",
    "    df = df.copy().sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "    # Map coordinates to a sensor region\n",
    "    df[\"region\"] = _map_coords_to_region(df, REGION_COORDS)\n",
    "\n",
    "    # Time-based features\n",
    "    df['hour'] = (df['timestamp'].dt.hour).astype('int8')\n",
    "    df['day_of_week'] = (df['timestamp'].dt.dayofweek).astype('int8')\n",
    "    df['day_of_month'] = (df['timestamp'].dt.day).astype('int8')\n",
    "    df['month'] = (df['timestamp'].dt.month).astype('int8')\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(bool)\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "\n",
    "    # Lag features\n",
    "    for lag in [1, 2, 3, 6, 12, 24, 48, 72, 168]:\n",
    "        df[f'air_temperature_lag_{lag}h'] = df['air_temperature_avg'].shift(lag)\n",
    "\n",
    "    # Rolling statistics\n",
    "    for window in [6, 12, 24, 72, 168]:\n",
    "        min_valid = max(1, window // 2)\n",
    "        df[f'air_temperature_rolling_mean_{window}h'] = df['air_temperature_avg'].shift(1).rolling(window, min_periods=min_valid).mean()\n",
    "        df[f'air_temperature_rolling_std_{window}h'] = df['air_temperature_avg'].shift(1).rolling(window, min_periods=min_valid).std()\n",
    "        df[f'air_temperature_rolling_min_{window}h'] = df['air_temperature_avg'].shift(1).rolling(window, min_periods=min_valid).min()\n",
    "        df[f'air_temperature_rolling_max_{window}h'] = df['air_temperature_avg'].shift(1).rolling(window, min_periods=min_valid).max()\n",
    "\n",
    "    df_clean = df.dropna()\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "def _map_coords_to_region(df: pd.DataFrame, region_coords: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    For each row in df (with latitude/longitude) find the nearest region from region_coords.\n",
    "    Returns a pandas Series of region names aligned with df.\n",
    "    \"\"\"\n",
    "    # df: N x 2 (lat, lon)\n",
    "    sensor_xy = df[[\"latitude\", \"longitude\"]].to_numpy()  # shape (N, 2)\n",
    "    # region_coords: M x 2 (lat, lon)\n",
    "    region_xy = region_coords[[\"latitude\", \"longitude\"]].to_numpy()  # shape (M, 2)\n",
    "\n",
    "    # compute squared distances (N, M)\n",
    "    # distance^2 = (lat1 - lat2)^2 + (lon1 - lon2)^2\n",
    "    diff_lat = sensor_xy[:, [0]] - region_xy[:, 0]  # (N, 1) - (M,) -> (N, M)\n",
    "    diff_lon = sensor_xy[:, [1]] - region_xy[:, 1]\n",
    "    dist_sq = diff_lat**2 + diff_lon**2  # (N, M)\n",
    "\n",
    "    # index of closest region for each sensor row\n",
    "    nearest_idx = dist_sq.argmin(axis=1)  # (N,)\n",
    "\n",
    "    # map to region names\n",
    "    regions = region_coords[\"region\"].to_numpy()\n",
    "    return pd.Series(regions[nearest_idx], index=df.index, name=\"region\")\n",
    "\n",
    "def apply_func_to_groups(df: pd.DataFrame, group_col: str, func: Callable[[pd.DataFrame], pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"Apply a function to each group in the DataFrame and combine results\"\"\"\n",
    "    grouped = df.groupby(group_col)\n",
    "    processed_groups = []\n",
    "\n",
    "    for name, group in grouped:\n",
    "        processed_group = func(group)\n",
    "        processed_groups.append(processed_group)\n",
    "\n",
    "    return pd.concat(processed_groups).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "34acdf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-10 22:25:31,657 WARNING: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n",
      "2025-11-10 22:25:31,700 WARNING: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n",
      "2025-11-10 22:25:31,801 WARNING: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n",
      "2025-11-10 22:25:32,278 WARNING: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n",
      "2025-11-10 22:25:32,743 WARNING: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pm25_daily_df = apply_func_to_groups(pm25_daily_df, 'region', regression_features_pm25_daily)\n",
    "pm25_hourly_df = apply_func_to_groups(pm25_hourly_df, 'region', regression_features_pm25_hourly)\n",
    "wind_direction_df = apply_func_to_groups(wind_direction_df, 'station_name', regression_features_wind_direction)\n",
    "wind_speed_df = apply_func_to_groups(wind_speed_df, 'station_name', regression_features_wind_speed)\n",
    "air_temperature_df = apply_func_to_groups(air_temperature_df, 'station_name', regression_features_air_temperature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4a2ae4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp                datetime64[ns]\n",
      "pm25                            float64\n",
      "region                         category\n",
      "day_of_week                        int8\n",
      "day_of_month                       int8\n",
      "month                              int8\n",
      "year                              int32\n",
      "is_weekend                        int64\n",
      "pm25_lag_1d                     float64\n",
      "pm25_lag_2d                     float64\n",
      "pm25_lag_3d                     float64\n",
      "pm25_lag_4d                     float64\n",
      "pm25_lag_5d                     float64\n",
      "pm25_lag_6d                     float64\n",
      "pm25_lag_7d                     float64\n",
      "pm25_lag_14d                    float64\n",
      "pm25_lag_28d                    float64\n",
      "pm25_rolling_mean_3d            float64\n",
      "pm25_rolling_std_3d             float64\n",
      "pm25_rolling_min_3d             float64\n",
      "pm25_rolling_max_3d             float64\n",
      "pm25_rolling_mean_7d            float64\n",
      "pm25_rolling_std_7d             float64\n",
      "pm25_rolling_min_7d             float64\n",
      "pm25_rolling_max_7d             float64\n",
      "pm25_rolling_mean_14d           float64\n",
      "pm25_rolling_std_14d            float64\n",
      "pm25_rolling_min_14d            float64\n",
      "pm25_rolling_max_14d            float64\n",
      "pm25_rolling_mean_28d           float64\n",
      "pm25_rolling_std_28d            float64\n",
      "pm25_rolling_min_28d            float64\n",
      "pm25_rolling_max_28d            float64\n",
      "dtype: object\n",
      "timestamp                 datetime64[ns, UTC+08:00]\n",
      "pm25                                        float64\n",
      "region                                     category\n",
      "hour                                           int8\n",
      "day_of_week                                    int8\n",
      "day_of_month                                   int8\n",
      "month                                          int8\n",
      "year                                          int32\n",
      "is_weekend                                     bool\n",
      "pm25_lag_1h                                 float64\n",
      "pm25_lag_2h                                 float64\n",
      "pm25_lag_3h                                 float64\n",
      "pm25_lag_6h                                 float64\n",
      "pm25_lag_12h                                float64\n",
      "pm25_lag_24h                                float64\n",
      "pm25_rolling_mean_6h                        float64\n",
      "pm25_rolling_std_6h                         float64\n",
      "pm25_rolling_min_6h                         float64\n",
      "pm25_rolling_max_6h                         float64\n",
      "pm25_rolling_mean_12h                       float64\n",
      "pm25_rolling_std_12h                        float64\n",
      "pm25_rolling_min_12h                        float64\n",
      "pm25_rolling_max_12h                        float64\n",
      "pm25_rolling_mean_24h                       float64\n",
      "pm25_rolling_std_24h                        float64\n",
      "pm25_rolling_min_24h                        float64\n",
      "pm25_rolling_max_24h                        float64\n",
      "pm25_rolling_mean_72h                       float64\n",
      "pm25_rolling_std_72h                        float64\n",
      "pm25_rolling_min_72h                        float64\n",
      "pm25_rolling_max_72h                        float64\n",
      "pm25_rolling_mean_168h                      float64\n",
      "pm25_rolling_std_168h                       float64\n",
      "pm25_rolling_min_168h                       float64\n",
      "pm25_rolling_max_168h                       float64\n",
      "dtype: object\n",
      "timestamp                          datetime64[ns, UTC+08:00]\n",
      "station_name                                        category\n",
      "wind_direction_avg                                   float64\n",
      "wind_direction_std                                   float64\n",
      "reading_count                                        float64\n",
      "latitude                                             float64\n",
      "longitude                                            float64\n",
      "region                                                object\n",
      "hour                                                    int8\n",
      "day_of_week                                             int8\n",
      "day_of_month                                            int8\n",
      "month                                                   int8\n",
      "year                                                   int32\n",
      "is_weekend                                              bool\n",
      "wind_u                                               float64\n",
      "wind_v                                               float64\n",
      "wind_u_lag_1h                                        float64\n",
      "wind_v_lag_1h                                        float64\n",
      "wind_direction_lag_1h                                float64\n",
      "wind_u_lag_2h                                        float64\n",
      "wind_v_lag_2h                                        float64\n",
      "wind_direction_lag_2h                                float64\n",
      "wind_u_lag_3h                                        float64\n",
      "wind_v_lag_3h                                        float64\n",
      "wind_direction_lag_3h                                float64\n",
      "wind_u_lag_6h                                        float64\n",
      "wind_v_lag_6h                                        float64\n",
      "wind_direction_lag_6h                                float64\n",
      "wind_u_lag_12h                                       float64\n",
      "wind_v_lag_12h                                       float64\n",
      "wind_direction_lag_12h                               float64\n",
      "wind_u_lag_24h                                       float64\n",
      "wind_v_lag_24h                                       float64\n",
      "wind_direction_lag_24h                               float64\n",
      "wind_u_lag_48h                                       float64\n",
      "wind_v_lag_48h                                       float64\n",
      "wind_direction_lag_48h                               float64\n",
      "wind_u_lag_72h                                       float64\n",
      "wind_v_lag_72h                                       float64\n",
      "wind_direction_lag_72h                               float64\n",
      "wind_u_lag_168h                                      float64\n",
      "wind_v_lag_168h                                      float64\n",
      "wind_direction_lag_168h                              float64\n",
      "wind_u_rolling_mean_6h                               float64\n",
      "wind_v_rolling_mean_6h                               float64\n",
      "direction_std_rolling_mean_6h                        float64\n",
      "wind_u_rolling_mean_12h                              float64\n",
      "wind_v_rolling_mean_12h                              float64\n",
      "direction_std_rolling_mean_12h                       float64\n",
      "wind_u_rolling_mean_24h                              float64\n",
      "wind_v_rolling_mean_24h                              float64\n",
      "direction_std_rolling_mean_24h                       float64\n",
      "wind_u_rolling_mean_72h                              float64\n",
      "wind_v_rolling_mean_72h                              float64\n",
      "direction_std_rolling_mean_72h                       float64\n",
      "wind_u_rolling_mean_168h                             float64\n",
      "wind_v_rolling_mean_168h                             float64\n",
      "direction_std_rolling_mean_168h                      float64\n",
      "dtype: object\n",
      "timestamp                       datetime64[ns, UTC+08:00]\n",
      "station_name                                     category\n",
      "wind_speed_avg                                    float64\n",
      "reading_count                                     float64\n",
      "latitude                                          float64\n",
      "longitude                                         float64\n",
      "region                                             object\n",
      "hour                                                 int8\n",
      "day_of_week                                          int8\n",
      "day_of_month                                         int8\n",
      "month                                                int8\n",
      "year                                                int32\n",
      "is_weekend                                           bool\n",
      "wind_speed_lag_1h                                 float64\n",
      "wind_speed_lag_2h                                 float64\n",
      "wind_speed_lag_3h                                 float64\n",
      "wind_speed_lag_6h                                 float64\n",
      "wind_speed_lag_12h                                float64\n",
      "wind_speed_lag_24h                                float64\n",
      "wind_speed_lag_48h                                float64\n",
      "wind_speed_lag_72h                                float64\n",
      "wind_speed_lag_168h                               float64\n",
      "wind_speed_rolling_mean_6h                        float64\n",
      "wind_speed_rolling_std_6h                         float64\n",
      "wind_speed_rolling_min_6h                         float64\n",
      "wind_speed_rolling_max_6h                         float64\n",
      "wind_speed_rolling_mean_12h                       float64\n",
      "wind_speed_rolling_std_12h                        float64\n",
      "wind_speed_rolling_min_12h                        float64\n",
      "wind_speed_rolling_max_12h                        float64\n",
      "wind_speed_rolling_mean_24h                       float64\n",
      "wind_speed_rolling_std_24h                        float64\n",
      "wind_speed_rolling_min_24h                        float64\n",
      "wind_speed_rolling_max_24h                        float64\n",
      "wind_speed_rolling_mean_72h                       float64\n",
      "wind_speed_rolling_std_72h                        float64\n",
      "wind_speed_rolling_min_72h                        float64\n",
      "wind_speed_rolling_max_72h                        float64\n",
      "wind_speed_rolling_mean_168h                      float64\n",
      "wind_speed_rolling_std_168h                       float64\n",
      "wind_speed_rolling_min_168h                       float64\n",
      "wind_speed_rolling_max_168h                       float64\n",
      "dtype: object\n",
      "timestamp                            datetime64[ns, UTC+08:00]\n",
      "station_name                                          category\n",
      "air_temperature_avg                                    float64\n",
      "reading_count                                          float64\n",
      "latitude                                               float64\n",
      "longitude                                              float64\n",
      "region                                                  object\n",
      "hour                                                      int8\n",
      "day_of_week                                               int8\n",
      "day_of_month                                              int8\n",
      "month                                                     int8\n",
      "year                                                     int32\n",
      "is_weekend                                                bool\n",
      "air_temperature_lag_1h                                 float64\n",
      "air_temperature_lag_2h                                 float64\n",
      "air_temperature_lag_3h                                 float64\n",
      "air_temperature_lag_6h                                 float64\n",
      "air_temperature_lag_12h                                float64\n",
      "air_temperature_lag_24h                                float64\n",
      "air_temperature_lag_48h                                float64\n",
      "air_temperature_lag_72h                                float64\n",
      "air_temperature_lag_168h                               float64\n",
      "air_temperature_rolling_mean_6h                        float64\n",
      "air_temperature_rolling_std_6h                         float64\n",
      "air_temperature_rolling_min_6h                         float64\n",
      "air_temperature_rolling_max_6h                         float64\n",
      "air_temperature_rolling_mean_12h                       float64\n",
      "air_temperature_rolling_std_12h                        float64\n",
      "air_temperature_rolling_min_12h                        float64\n",
      "air_temperature_rolling_max_12h                        float64\n",
      "air_temperature_rolling_mean_24h                       float64\n",
      "air_temperature_rolling_std_24h                        float64\n",
      "air_temperature_rolling_min_24h                        float64\n",
      "air_temperature_rolling_max_24h                        float64\n",
      "air_temperature_rolling_mean_72h                       float64\n",
      "air_temperature_rolling_std_72h                        float64\n",
      "air_temperature_rolling_min_72h                        float64\n",
      "air_temperature_rolling_max_72h                        float64\n",
      "air_temperature_rolling_mean_168h                      float64\n",
      "air_temperature_rolling_std_168h                       float64\n",
      "air_temperature_rolling_min_168h                       float64\n",
      "air_temperature_rolling_max_168h                       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print(pm25_daily_df.info())\n",
    "print(pm25_daily_df.dtypes)\n",
    "# print(pm25_daily_df.columns)\n",
    "# print(pm25_hourly_df.info())\n",
    "print(pm25_hourly_df.dtypes)\n",
    "# print(pm25_hourly_df.columns)\n",
    "# print(wind_direction_df.info())\n",
    "print(wind_direction_df.dtypes)\n",
    "# print(wind_direction_df.columns)\n",
    "# print(wind_speed_df.info())\n",
    "print(wind_speed_df.dtypes)\n",
    "# print(wind_speed_df.columns)\n",
    "# print(air_temperature_df.region.head(200000))\n",
    "print(air_temperature_df.dtypes)\n",
    "# print(air_temperature_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c38ca06",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "42b95ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-10 22:25:33,168 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-11-10 22:25:33,172 INFO: Initializing external client\n",
      "2025-11-10 22:25:33,173 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-11-10 22:25:33,793 WARNING: UserWarning: The installed hopsworks client version 4.4.2 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-10 22:25:34,471 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1286307\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "project = hopsworks.login(engine=\"python\", project=\"terahidro2003\")\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d8b5e524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1286307/fs/1265775/fg/1668652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 100857/100857 | Elapsed Time: 00:04 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: pm25_hourly_1_offline_fg_materialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%6|1762809961.885|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.81.188:9093/bootstrap]: ssl://51.161.81.188:9093/1: Disconnected (after 49999ms in state UP, 1 identical error(s) suppressed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286307/jobs/named/pm25_hourly_1_offline_fg_materialization/executions\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1286307/fs/1265775/fg/1668654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 20774/20774 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: pm25_daily_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286307/jobs/named/pm25_daily_1_offline_fg_materialization/executions\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1286307/fs/1265775/fg/1668656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 303560/303560 | Elapsed Time: 00:18 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: wind_direction_hourly_1_offline_fg_materialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%6|1762810012.103|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.81.208:9093/bootstrap]: ssl://51.161.81.208:9093/2: Disconnected (after 99916ms in state UP, 1 identical error(s) suppressed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286307/jobs/named/wind_direction_hourly_1_offline_fg_materialization/executions\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1286307/fs/1265775/fg/1668657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 303561/303561 | Elapsed Time: 00:14 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: wind_speed_hourly_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286307/jobs/named/wind_speed_hourly_1_offline_fg_materialization/executions\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1286307/fs/1265775/fg/1668658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%6|1762810062.604|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.81.188:9093/bootstrap]: ssl://51.161.81.188:9093/1: Disconnected (after 50002ms in state UP, 1 identical error(s) suppressed)\n",
      "Uploading Dataframe: 100.00% |██████████| Rows 325889/325889 | Elapsed Time: 00:15 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_temperature_hourly_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286307/jobs/named/air_temperature_hourly_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('air_temperature_hourly_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%script echo skipping --no-raise-error\n",
    "\n",
    "# Feature Group 1: Hourly PM2.5 features\n",
    "fg_pm25_hourly = fs.get_or_create_feature_group(\n",
    "    name=\"pm25_hourly\",\n",
    "    description=\"Hourly PM2.5 features with short-term patterns\",\n",
    "    version=1,\n",
    "    primary_key=[\"region\", \"timestamp\"],\n",
    "    event_time=\"timestamp\",\n",
    ")\n",
    "fg_pm25_hourly.insert(pm25_hourly_df)\n",
    "\n",
    "# Feature Group 2: Daily PM2.5 features\n",
    "fg_pm25_daily = fs.get_or_create_feature_group(\n",
    "    name=\"pm25_daily\",\n",
    "    description=\"Daily PM2.5 aggregations for long-term trends\",\n",
    "    version=1,\n",
    "    primary_key=[\"region\", \"timestamp\"],\n",
    "    event_time=\"timestamp\",\n",
    ")\n",
    "fg_pm25_daily.insert(pm25_daily_df)\n",
    "\n",
    "# Feature Group 3: Wind Direction features\n",
    "fg_wind_direction = fs.get_or_create_feature_group(\n",
    "    name=\"wind_direction_hourly\",\n",
    "    description=\"Wind direction features with vector components\",\n",
    "    version=1,\n",
    "    primary_key=[\"region\", \"timestamp\"],\n",
    "    event_time=\"timestamp\",\n",
    ")\n",
    "fg_wind_direction.insert(wind_direction_df)\n",
    "\n",
    "# Feature Group 4: Wind Speed features\n",
    "fg_wind_speed = fs.get_or_create_feature_group(\n",
    "    name=\"wind_speed_hourly\",\n",
    "    description=\"Wind speed features\",\n",
    "    version=1,\n",
    "    primary_key=[\"region\", \"timestamp\"],\n",
    "    event_time=\"timestamp\",\n",
    ")\n",
    "fg_wind_speed.insert(wind_speed_df)\n",
    "\n",
    "# Feature Group 5: Air Temperature features\n",
    "fg_air_temperature = fs.get_or_create_feature_group(\n",
    "    name=\"air_temperature_hourly\",\n",
    "    description=\"Air temperature features\",\n",
    "    version=1,\n",
    "    primary_key=[\"region\", \"timestamp\"],\n",
    "    event_time=\"timestamp\",\n",
    ")\n",
    "fg_air_temperature.insert(air_temperature_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2241cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'wind_speed_avg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/Data/KTH/ML/air-quality-prediction/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'wind_speed_avg'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[116]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m FORECASRT_HOURS_AHEAD = \u001b[32m24\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Target variables\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwind_speed_avg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.shift(-FORECASRT_HOURS_AHEAD)\n\u001b[32m      5\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mwind_direction_avg\u001b[39m\u001b[33m'\u001b[39m].shift(-FORECASRT_HOURS_AHEAD)\n\u001b[32m      7\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mpm25\u001b[39m\u001b[33m'\u001b[39m].shift(-FORECASRT_HOURS_AHEAD)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/Data/KTH/ML/air-quality-prediction/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/Data/KTH/ML/air-quality-prediction/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'wind_speed_avg'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%6|1762810160.995|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.80.189:9093/bootstrap]: ssl://51.161.80.189:9093/0: Disconnected (after 97931ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1762810211.584|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.81.188:9093/bootstrap]: ssl://51.161.81.188:9093/1: Disconnected (after 50081ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1762810262.101|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.80.189:9093/bootstrap]: ssl://51.161.80.189:9093/0: Disconnected (after 50002ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1762810312.347|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.81.208:9093/bootstrap]: ssl://51.161.81.208:9093/2: Disconnected (after 100061ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1762810362.805|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.80.189:9093/bootstrap]: ssl://51.161.80.189:9093/0: Disconnected (after 50001ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1762810461.036|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.81.188:9093/bootstrap]: ssl://51.161.81.188:9093/1: Disconnected (after 97711ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1762810511.479|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.81.208:9093/bootstrap]: ssl://51.161.81.208:9093/2: Disconnected (after 50004ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1762810561.947|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.80.189:9093/bootstrap]: ssl://51.161.80.189:9093/0: Disconnected (after 50004ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1762810612.070|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.81.208:9093/bootstrap]: ssl://51.161.81.208:9093/2: Disconnected (after 99664ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1762810662.544|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.80.189:9093/bootstrap]: ssl://51.161.80.189:9093/0: Disconnected (after 49997ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1762810760.922|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.81.208:9093/bootstrap]: ssl://51.161.81.208:9093/2: Disconnected (after 148184ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1762810811.458|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.80.189:9093/bootstrap]: ssl://51.161.80.189:9093/0: Disconnected (after 50072ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1762810862.147|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.81.188:9093/bootstrap]: ssl://51.161.81.188:9093/1: Disconnected (after 50139ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1762810912.666|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.80.189:9093/bootstrap]: ssl://51.161.80.189:9093/0: Disconnected (after 50046ms in state UP, 1 identical error(s) suppressed)\n",
      "%6|1762810912.756|FAIL|rdkafka#producer-31| [thrd:ssl://51.161.81.188:9093/bootstrap]: ssl://51.161.81.188:9093/1: Disconnected (after 50001ms in state UP, 1 identical error(s) suppressed)\n"
     ]
    }
   ],
   "source": [
    "FORECASRT_HOURS_AHEAD = 24\n",
    "# Target variables\n",
    "df['target'] = df['wind_speed_avg'].shift(-FORECASRT_HOURS_AHEAD)\n",
    "\n",
    "df['target'] = df['wind_direction_avg'].shift(-FORECASRT_HOURS_AHEAD)\n",
    "\n",
    "df['target'] = df['pm25'].shift(-FORECASRT_HOURS_AHEAD)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "air-quality-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
