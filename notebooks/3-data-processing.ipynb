{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f314f9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e54b6cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "333ce09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory based on root folder\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "\n",
    "# GET ABSOLUTE PATH\n",
    "head, _ = os.path.split(os.getcwd()) # Get parent directory, from notebooks\n",
    "DATA_DIR = os.path.join(head, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b71625",
   "metadata": {},
   "source": [
    "# DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "151920ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename: str, prefix: str=\"\", data_dir: os.PathLike=DATA_DIR):\n",
    "    \"\"\"Load data file with a specific prefix\"\"\"\n",
    "\n",
    "    filename = f\"{prefix}-{filename}\" if len(prefix) else filename\n",
    "\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"Data file not found: {filepath}. Run scraping first.\")\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    # if 'date' in df.columns:\n",
    "    #     df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# ============================================================================\n",
    "# DATA LOADING FUNCTIONS WINDSPEED AND DIRECTION\n",
    "# ============================================================================\n",
    "\n",
    "def load_all_stations(input_dir: os.PathLike =DATA_DIR, file_pattern: str=\"\"):\n",
    "    \"\"\"Load data for all stations\"\"\"\n",
    "    import glob\n",
    "    pattern = os.path.join(input_dir, file_pattern)\n",
    "    station_files = glob.glob(pattern)\n",
    "\n",
    "    station_dfs = []\n",
    "    for filepath in station_files:\n",
    "        filename = os.path.basename(filepath)\n",
    "        station_dfs.append(load_data(filename, data_dir=input_dir))\n",
    "\n",
    "    return pd.concat(station_dfs).reset_index(drop=True)\n",
    "\n",
    "def load_stations_metadata(input_dir: os.PathLike=DATA_DIR):\n",
    "    \"\"\"Load stations metadata\"\"\"\n",
    "    filename = os.path.join(input_dir, \"stations_metadata.csv\")\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(f\"Metadata file not found: {filename}\")\n",
    "\n",
    "    return pd.read_csv(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f38dcb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGIONS_PREFIX = ['east', 'west', 'north', 'south', 'central']\n",
    "\n",
    "pm25_hourly_df_temp = {region: load_data(f\"pm2.5-hourly-230701-251101.csv\", prefix=region, data_dir=os.path.join(DATA_DIR, \"pm2.5-hourly\")) for region in REGIONS_PREFIX}\n",
    "pm25_hourly_df = []\n",
    "for region, df in pm25_hourly_df_temp.items():\n",
    "    df['region'] = region\n",
    "    pm25_hourly_df.append(df)\n",
    "pm25_hourly_df = pd.concat(pm25_hourly_df).reset_index(drop=True)\n",
    "pm25_hourly_df['region'] = pm25_hourly_df['region'].astype('category')\n",
    "pm25_hourly_df['pm25'] = pd.to_numeric(pm25_hourly_df['pm25'], errors='coerce')\n",
    "pm25_hourly_df.drop(columns=['date'], axis=1, inplace=True)\n",
    "del pm25_hourly_df_temp\n",
    "\n",
    "\n",
    "pm25_daily_df_temp = {region: load_data(f\"singapore-air-quality.csv\", prefix=region, data_dir=os.path.join(DATA_DIR, \"pm2.5-daily\")) for region in REGIONS_PREFIX}\n",
    "pm25_daily_df = []\n",
    "for region, df in pm25_daily_df_temp.items():\n",
    "    df['region'] = region\n",
    "    pm25_daily_df.append(df)\n",
    "pm25_daily_df = pd.concat(pm25_daily_df).reset_index(drop=True)\n",
    "pm25_daily_df['region'] = pm25_daily_df['region'].astype('category')\n",
    "pm25_daily_df.drop(columns=['pm10', 'o3', 'no2', 'so2', 'co', 'psi'], axis=1, inplace=True)\n",
    "pm25_daily_df['pm25'] = pd.to_numeric(pm25_daily_df['pm25'], errors='coerce')\n",
    "del pm25_daily_df_temp\n",
    "\n",
    "\n",
    "wind_speed_df = load_all_stations(os.path.join(DATA_DIR, 'wind-speed'), file_pattern=\"*-wind-speed-hourly-*.csv\")\n",
    "wind_speed_df.drop(columns=['last_update'], axis=1, inplace=True)\n",
    "wind_speed_df['station_name'] = wind_speed_df['station_name'].astype('category')\n",
    "\n",
    "wind_direction_df = load_all_stations(os.path.join(DATA_DIR, 'wind-direction'), file_pattern=\"*-wind-direction-hourly-*.csv\")\n",
    "wind_direction_df.drop(columns=['last_update'], axis=1, inplace=True)\n",
    "wind_direction_df['station_name'] = wind_direction_df['station_name'].astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcf6bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLAYGROUND AREA TO VIEW LOADED DATAFRAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a6339d",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING FOR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2522a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "def regression_features_pm25_daily(df: pd.DataFrame):\n",
    "    \"\"\"Prepare features for time series regression modeling\"\"\"\n",
    "    df = df.copy().sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "    # Time-based features\n",
    "    df['day_of_week'] = (df['timestamp'].dt.dayofweek).astype('int8')\n",
    "    df['day_of_month'] = (df['timestamp'].dt.day).astype('int8')\n",
    "    df['month'] = (df['timestamp'].dt.month).astype('int8')\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "    # Lag features\n",
    "    for lag in [1, 2, 3, 4, 5, 6, 7, 14, 28]:\n",
    "        df[f'pm25_lag_{lag}d'] = df['pm25'].shift(lag)\n",
    "\n",
    "    # Rolling statistics\n",
    "    for window in [3, 7, 14, 28]:\n",
    "        min_valid = max(1, window // 2)\n",
    "        df[f'pm25_rolling_mean_{window}d'] = df['pm25'].shift(1).rolling(window, min_periods=min_valid).mean()\n",
    "        df[f'pm25_rolling_std_{window}d'] = df['pm25'].shift(1).rolling(window, min_periods=min_valid).std()\n",
    "        df[f'pm25_rolling_min_{window}d'] = df['pm25'].shift(1).rolling(window, min_periods=min_valid).min()\n",
    "        df[f'pm25_rolling_max_{window}d'] = df['pm25'].shift(1).rolling(window, min_periods=min_valid).max()\n",
    "\n",
    "    df_clean = df.dropna()\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def regression_features_pm25_hourly(df: pd.DataFrame):\n",
    "    \"\"\"Prepare features for time series regression modeling\"\"\"\n",
    "    df = df.copy().sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "    # Time-based features\n",
    "    df['hour'] = (df['timestamp'].dt.hour).astype('int8')\n",
    "    df['day_of_week'] = (df['timestamp'].dt.dayofweek).astype('int8')\n",
    "    df['day_of_month'] = (df['timestamp'].dt.day).astype('int8')\n",
    "    df['month'] = (df['timestamp'].dt.month).astype('int8')\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(bool)\n",
    "\n",
    "    # Lag features\n",
    "    for lag in [1, 2, 3, 6, 12, 24]:\n",
    "        df[f'pm25_lag_{lag}h'] = df['pm25'].shift(lag)\n",
    "\n",
    "    # Rolling statistics\n",
    "    for window in [6, 12, 24, 72, 168]:\n",
    "        min_valid = max(1, window // 2)\n",
    "        df[f'pm25_rolling_mean_{window}h'] = df['pm25'].shift(1).rolling(window, min_periods=min_valid).mean()\n",
    "        df[f'pm25_rolling_std_{window}h'] = df['pm25'].shift(1).rolling(window, min_periods=min_valid).std()\n",
    "        df[f'pm25_rolling_min_{window}h'] = df['pm25'].shift(1).rolling(window, min_periods=min_valid).min()\n",
    "        df[f'pm25_rolling_max_{window}h'] = df['pm25'].shift(1).rolling(window, min_periods=min_valid).max()\n",
    "\n",
    "    df_clean = df.dropna()\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def regression_features_wind_direction(df: pd.DataFrame):\n",
    "    \"\"\"Prepare features for time series regression modeling\"\"\"\n",
    "    df = df.copy().sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "    # Time-based features\n",
    "    df['hour'] = (df['timestamp'].dt.hour).astype('int8')\n",
    "    df['day_of_week'] = (df['timestamp'].dt.dayofweek).astype('int8')\n",
    "    df['day_of_month'] = (df['timestamp'].dt.day).astype('int8')\n",
    "    df['month'] = (df['timestamp'].dt.month).astype('int8')\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(bool)\n",
    "\n",
    "    # Convert direction to vector components (recommended for modeling)\n",
    "    df['wind_u'] = -np.sin(np.deg2rad(df['wind_direction_avg']))\n",
    "    df['wind_v'] = -np.cos(np.deg2rad(df['wind_direction_avg']))\n",
    "\n",
    "    # Lag features (using vector components)\n",
    "    for lag in [1, 2, 3, 6, 12, 24, 48, 72, 168]:\n",
    "        df[f'wind_u_lag_{lag}h'] = df['wind_u'].shift(lag)\n",
    "        df[f'wind_v_lag_{lag}h'] = df['wind_v'].shift(lag)\n",
    "        df[f'wind_direction_lag_{lag}h'] = df['wind_direction_avg'].shift(lag)\n",
    "\n",
    "    # Rolling statistics\n",
    "    for window in [6, 12, 24, 72, 168]:\n",
    "        min_valid = max(1, window // 2)\n",
    "        df[f'wind_u_rolling_mean_{window}h'] = df['wind_u'].shift(1).rolling(window, min_periods=min_valid).mean()\n",
    "        df[f'wind_v_rolling_mean_{window}h'] = df['wind_v'].shift(1).rolling(window, min_periods=min_valid).mean()\n",
    "        df[f'direction_std_rolling_mean_{window}h'] = df['wind_direction_std'].shift(1).rolling(window, min_periods=min_valid).mean()\n",
    "\n",
    "    df_clean = df.dropna()\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def regression_features_wind_speed(df: pd.DataFrame):\n",
    "    \"\"\"Prepare features for time series regression modeling\"\"\"\n",
    "    df = df.copy().sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "    # Time-based features\n",
    "    df['hour'] = (df['timestamp'].dt.hour).astype('int8')\n",
    "    df['day_of_week'] = (df['timestamp'].dt.dayofweek).astype('int8')\n",
    "    df['day_of_month'] = (df['timestamp'].dt.day).astype('int8')\n",
    "    df['month'] = (df['timestamp'].dt.month).astype('int8')\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(bool)\n",
    "\n",
    "    # Lag features\n",
    "    for lag in [1, 2, 3, 6, 12, 24, 48, 72, 168]:\n",
    "        df[f'wind_speed_lag_{lag}h'] = df['wind_speed_avg'].shift(lag)\n",
    "\n",
    "    # Rolling statistics\n",
    "    for window in [6, 12, 24, 72, 168]:\n",
    "        min_valid = max(1, window // 2)\n",
    "        df[f'wind_speed_rolling_mean_{window}h'] = df['wind_speed_avg'].shift(1).rolling(window, min_periods=min_valid).mean()\n",
    "        df[f'wind_speed_rolling_std_{window}h'] = df['wind_speed_avg'].shift(1).rolling(window, min_periods=min_valid).std()\n",
    "        df[f'wind_speed_rolling_min_{window}h'] = df['wind_speed_avg'].shift(1).rolling(window, min_periods=min_valid).min()\n",
    "        df[f'wind_speed_rolling_max_{window}h'] = df['wind_speed_avg'].shift(1).rolling(window, min_periods=min_valid).max()\n",
    "\n",
    "    df_clean = df.dropna()\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def apply_func_to_groups(df: pd.DataFrame, group_col: str, func: Callable[[pd.DataFrame], pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"Apply a function to each group in the DataFrame and combine results\"\"\"\n",
    "    grouped = df.groupby(group_col)\n",
    "    processed_groups = []\n",
    "\n",
    "    for name, group in grouped:\n",
    "        processed_group = func(group)\n",
    "        processed_groups.append(processed_group)\n",
    "\n",
    "    return pd.concat(processed_groups).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34acdf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n"
     ]
    }
   ],
   "source": [
    "pm25_daily_df = apply_func_to_groups(pm25_daily_df, 'region', regression_features_pm25_daily)\n",
    "pm25_hourly_df = apply_func_to_groups(pm25_hourly_df, 'region', regression_features_pm25_hourly)\n",
    "wind_direction_df = apply_func_to_groups(wind_direction_df, 'station_name', regression_features_wind_direction)\n",
    "wind_speed_df = apply_func_to_groups(wind_speed_df, 'station_name', regression_features_wind_speed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a2ae4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20774 entries, 0 to 20773\n",
      "Data columns (total 33 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   timestamp              20774 non-null  datetime64[ns]\n",
      " 1   pm25                   20774 non-null  float64       \n",
      " 2   region                 20774 non-null  category      \n",
      " 3   day_of_week            20774 non-null  int8          \n",
      " 4   day_of_month           20774 non-null  int8          \n",
      " 5   month                  20774 non-null  int8          \n",
      " 6   year                   20774 non-null  int32         \n",
      " 7   is_weekend             20774 non-null  int64         \n",
      " 8   pm25_lag_1d            20774 non-null  float64       \n",
      " 9   pm25_lag_2d            20774 non-null  float64       \n",
      " 10  pm25_lag_3d            20774 non-null  float64       \n",
      " 11  pm25_lag_4d            20774 non-null  float64       \n",
      " 12  pm25_lag_5d            20774 non-null  float64       \n",
      " 13  pm25_lag_6d            20774 non-null  float64       \n",
      " 14  pm25_lag_7d            20774 non-null  float64       \n",
      " 15  pm25_lag_14d           20774 non-null  float64       \n",
      " 16  pm25_lag_28d           20774 non-null  float64       \n",
      " 17  pm25_rolling_mean_3d   20774 non-null  float64       \n",
      " 18  pm25_rolling_std_3d    20774 non-null  float64       \n",
      " 19  pm25_rolling_min_3d    20774 non-null  float64       \n",
      " 20  pm25_rolling_max_3d    20774 non-null  float64       \n",
      " 21  pm25_rolling_mean_7d   20774 non-null  float64       \n",
      " 22  pm25_rolling_std_7d    20774 non-null  float64       \n",
      " 23  pm25_rolling_min_7d    20774 non-null  float64       \n",
      " 24  pm25_rolling_max_7d    20774 non-null  float64       \n",
      " 25  pm25_rolling_mean_14d  20774 non-null  float64       \n",
      " 26  pm25_rolling_std_14d   20774 non-null  float64       \n",
      " 27  pm25_rolling_min_14d   20774 non-null  float64       \n",
      " 28  pm25_rolling_max_14d   20774 non-null  float64       \n",
      " 29  pm25_rolling_mean_28d  20774 non-null  float64       \n",
      " 30  pm25_rolling_std_28d   20774 non-null  float64       \n",
      " 31  pm25_rolling_min_28d   20774 non-null  float64       \n",
      " 32  pm25_rolling_max_28d   20774 non-null  float64       \n",
      "dtypes: category(1), datetime64[ns](1), float64(26), int32(1), int64(1), int8(3)\n",
      "memory usage: 4.6 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100857 entries, 0 to 100856\n",
      "Data columns (total 35 columns):\n",
      " #   Column                  Non-Null Count   Dtype                    \n",
      "---  ------                  --------------   -----                    \n",
      " 0   timestamp               100857 non-null  datetime64[ns, UTC+08:00]\n",
      " 1   pm25                    100857 non-null  float64                  \n",
      " 2   region                  100857 non-null  category                 \n",
      " 3   hour                    100857 non-null  int8                     \n",
      " 4   day_of_week             100857 non-null  int8                     \n",
      " 5   day_of_month            100857 non-null  int8                     \n",
      " 6   month                   100857 non-null  int8                     \n",
      " 7   year                    100857 non-null  int32                    \n",
      " 8   is_weekend              100857 non-null  bool                     \n",
      " 9   pm25_lag_1h             100857 non-null  float64                  \n",
      " 10  pm25_lag_2h             100857 non-null  float64                  \n",
      " 11  pm25_lag_3h             100857 non-null  float64                  \n",
      " 12  pm25_lag_6h             100857 non-null  float64                  \n",
      " 13  pm25_lag_12h            100857 non-null  float64                  \n",
      " 14  pm25_lag_24h            100857 non-null  float64                  \n",
      " 15  pm25_rolling_mean_6h    100857 non-null  float64                  \n",
      " 16  pm25_rolling_std_6h     100857 non-null  float64                  \n",
      " 17  pm25_rolling_min_6h     100857 non-null  float64                  \n",
      " 18  pm25_rolling_max_6h     100857 non-null  float64                  \n",
      " 19  pm25_rolling_mean_12h   100857 non-null  float64                  \n",
      " 20  pm25_rolling_std_12h    100857 non-null  float64                  \n",
      " 21  pm25_rolling_min_12h    100857 non-null  float64                  \n",
      " 22  pm25_rolling_max_12h    100857 non-null  float64                  \n",
      " 23  pm25_rolling_mean_24h   100857 non-null  float64                  \n",
      " 24  pm25_rolling_std_24h    100857 non-null  float64                  \n",
      " 25  pm25_rolling_min_24h    100857 non-null  float64                  \n",
      " 26  pm25_rolling_max_24h    100857 non-null  float64                  \n",
      " 27  pm25_rolling_mean_72h   100857 non-null  float64                  \n",
      " 28  pm25_rolling_std_72h    100857 non-null  float64                  \n",
      " 29  pm25_rolling_min_72h    100857 non-null  float64                  \n",
      " 30  pm25_rolling_max_72h    100857 non-null  float64                  \n",
      " 31  pm25_rolling_mean_168h  100857 non-null  float64                  \n",
      " 32  pm25_rolling_std_168h   100857 non-null  float64                  \n",
      " 33  pm25_rolling_min_168h   100857 non-null  float64                  \n",
      " 34  pm25_rolling_max_168h   100857 non-null  float64                  \n",
      "dtypes: bool(1), category(1), datetime64[ns, UTC+08:00](1), float64(27), int32(1), int8(4)\n",
      "memory usage: 22.5 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303560 entries, 0 to 303559\n",
      "Data columns (total 57 columns):\n",
      " #   Column                           Non-Null Count   Dtype                    \n",
      "---  ------                           --------------   -----                    \n",
      " 0   timestamp                        303560 non-null  datetime64[ns, UTC+08:00]\n",
      " 1   station_name                     303560 non-null  category                 \n",
      " 2   wind_direction_avg               303560 non-null  float64                  \n",
      " 3   wind_direction_std               303560 non-null  float64                  \n",
      " 4   reading_count                    303560 non-null  float64                  \n",
      " 5   latitude                         303560 non-null  float64                  \n",
      " 6   longitude                        303560 non-null  float64                  \n",
      " 7   hour                             303560 non-null  int8                     \n",
      " 8   day_of_week                      303560 non-null  int8                     \n",
      " 9   day_of_month                     303560 non-null  int8                     \n",
      " 10  month                            303560 non-null  int8                     \n",
      " 11  year                             303560 non-null  int32                    \n",
      " 12  is_weekend                       303560 non-null  bool                     \n",
      " 13  wind_u                           303560 non-null  float64                  \n",
      " 14  wind_v                           303560 non-null  float64                  \n",
      " 15  wind_u_lag_1h                    303560 non-null  float64                  \n",
      " 16  wind_v_lag_1h                    303560 non-null  float64                  \n",
      " 17  wind_direction_lag_1h            303560 non-null  float64                  \n",
      " 18  wind_u_lag_2h                    303560 non-null  float64                  \n",
      " 19  wind_v_lag_2h                    303560 non-null  float64                  \n",
      " 20  wind_direction_lag_2h            303560 non-null  float64                  \n",
      " 21  wind_u_lag_3h                    303560 non-null  float64                  \n",
      " 22  wind_v_lag_3h                    303560 non-null  float64                  \n",
      " 23  wind_direction_lag_3h            303560 non-null  float64                  \n",
      " 24  wind_u_lag_6h                    303560 non-null  float64                  \n",
      " 25  wind_v_lag_6h                    303560 non-null  float64                  \n",
      " 26  wind_direction_lag_6h            303560 non-null  float64                  \n",
      " 27  wind_u_lag_12h                   303560 non-null  float64                  \n",
      " 28  wind_v_lag_12h                   303560 non-null  float64                  \n",
      " 29  wind_direction_lag_12h           303560 non-null  float64                  \n",
      " 30  wind_u_lag_24h                   303560 non-null  float64                  \n",
      " 31  wind_v_lag_24h                   303560 non-null  float64                  \n",
      " 32  wind_direction_lag_24h           303560 non-null  float64                  \n",
      " 33  wind_u_lag_48h                   303560 non-null  float64                  \n",
      " 34  wind_v_lag_48h                   303560 non-null  float64                  \n",
      " 35  wind_direction_lag_48h           303560 non-null  float64                  \n",
      " 36  wind_u_lag_72h                   303560 non-null  float64                  \n",
      " 37  wind_v_lag_72h                   303560 non-null  float64                  \n",
      " 38  wind_direction_lag_72h           303560 non-null  float64                  \n",
      " 39  wind_u_lag_168h                  303560 non-null  float64                  \n",
      " 40  wind_v_lag_168h                  303560 non-null  float64                  \n",
      " 41  wind_direction_lag_168h          303560 non-null  float64                  \n",
      " 42  wind_u_rolling_mean_6h           303560 non-null  float64                  \n",
      " 43  wind_v_rolling_mean_6h           303560 non-null  float64                  \n",
      " 44  direction_std_rolling_mean_6h    303560 non-null  float64                  \n",
      " 45  wind_u_rolling_mean_12h          303560 non-null  float64                  \n",
      " 46  wind_v_rolling_mean_12h          303560 non-null  float64                  \n",
      " 47  direction_std_rolling_mean_12h   303560 non-null  float64                  \n",
      " 48  wind_u_rolling_mean_24h          303560 non-null  float64                  \n",
      " 49  wind_v_rolling_mean_24h          303560 non-null  float64                  \n",
      " 50  direction_std_rolling_mean_24h   303560 non-null  float64                  \n",
      " 51  wind_u_rolling_mean_72h          303560 non-null  float64                  \n",
      " 52  wind_v_rolling_mean_72h          303560 non-null  float64                  \n",
      " 53  direction_std_rolling_mean_72h   303560 non-null  float64                  \n",
      " 54  wind_u_rolling_mean_168h         303560 non-null  float64                  \n",
      " 55  wind_v_rolling_mean_168h         303560 non-null  float64                  \n",
      " 56  direction_std_rolling_mean_168h  303560 non-null  float64                  \n",
      "dtypes: bool(1), category(1), datetime64[ns, UTC+08:00](1), float64(49), int32(1), int8(4)\n",
      "memory usage: 118.7 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303561 entries, 0 to 303560\n",
      "Data columns (total 41 columns):\n",
      " #   Column                        Non-Null Count   Dtype                    \n",
      "---  ------                        --------------   -----                    \n",
      " 0   timestamp                     303561 non-null  datetime64[ns, UTC+08:00]\n",
      " 1   station_name                  303561 non-null  category                 \n",
      " 2   wind_speed_avg                303561 non-null  float64                  \n",
      " 3   reading_count                 303561 non-null  float64                  \n",
      " 4   latitude                      303561 non-null  float64                  \n",
      " 5   longitude                     303561 non-null  float64                  \n",
      " 6   hour                          303561 non-null  int8                     \n",
      " 7   day_of_week                   303561 non-null  int8                     \n",
      " 8   day_of_month                  303561 non-null  int8                     \n",
      " 9   month                         303561 non-null  int8                     \n",
      " 10  year                          303561 non-null  int32                    \n",
      " 11  is_weekend                    303561 non-null  bool                     \n",
      " 12  wind_speed_lag_1h             303561 non-null  float64                  \n",
      " 13  wind_speed_lag_2h             303561 non-null  float64                  \n",
      " 14  wind_speed_lag_3h             303561 non-null  float64                  \n",
      " 15  wind_speed_lag_6h             303561 non-null  float64                  \n",
      " 16  wind_speed_lag_12h            303561 non-null  float64                  \n",
      " 17  wind_speed_lag_24h            303561 non-null  float64                  \n",
      " 18  wind_speed_lag_48h            303561 non-null  float64                  \n",
      " 19  wind_speed_lag_72h            303561 non-null  float64                  \n",
      " 20  wind_speed_lag_168h           303561 non-null  float64                  \n",
      " 21  wind_speed_rolling_mean_6h    303561 non-null  float64                  \n",
      " 22  wind_speed_rolling_std_6h     303561 non-null  float64                  \n",
      " 23  wind_speed_rolling_min_6h     303561 non-null  float64                  \n",
      " 24  wind_speed_rolling_max_6h     303561 non-null  float64                  \n",
      " 25  wind_speed_rolling_mean_12h   303561 non-null  float64                  \n",
      " 26  wind_speed_rolling_std_12h    303561 non-null  float64                  \n",
      " 27  wind_speed_rolling_min_12h    303561 non-null  float64                  \n",
      " 28  wind_speed_rolling_max_12h    303561 non-null  float64                  \n",
      " 29  wind_speed_rolling_mean_24h   303561 non-null  float64                  \n",
      " 30  wind_speed_rolling_std_24h    303561 non-null  float64                  \n",
      " 31  wind_speed_rolling_min_24h    303561 non-null  float64                  \n",
      " 32  wind_speed_rolling_max_24h    303561 non-null  float64                  \n",
      " 33  wind_speed_rolling_mean_72h   303561 non-null  float64                  \n",
      " 34  wind_speed_rolling_std_72h    303561 non-null  float64                  \n",
      " 35  wind_speed_rolling_min_72h    303561 non-null  float64                  \n",
      " 36  wind_speed_rolling_max_72h    303561 non-null  float64                  \n",
      " 37  wind_speed_rolling_mean_168h  303561 non-null  float64                  \n",
      " 38  wind_speed_rolling_std_168h   303561 non-null  float64                  \n",
      " 39  wind_speed_rolling_min_168h   303561 non-null  float64                  \n",
      " 40  wind_speed_rolling_max_168h   303561 non-null  float64                  \n",
      "dtypes: bool(1), category(1), datetime64[ns, UTC+08:00](1), float64(33), int32(1), int8(4)\n",
      "memory usage: 81.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(pm25_daily_df.info())\n",
    "# print(pm25_daily_df.dtypes)\n",
    "# print(pm25_daily_df.columns)\n",
    "print(pm25_hourly_df.info())\n",
    "# print(pm25_hourly_df.dtypes)\n",
    "# print(pm25_hourly_df.columns)\n",
    "print(wind_direction_df.info())\n",
    "# print(wind_direction_df.dtypes)\n",
    "# print(wind_direction_df.columns)\n",
    "print(wind_speed_df.info())\n",
    "# print(wind_speed_df.dtypes)\n",
    "# print(wind_speed_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c38ca06",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42b95ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-09 16:47:31,522 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-11-09 16:47:31,525 INFO: Initializing external client\n",
      "2025-11-09 16:47:31,525 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.4.2 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-09 16:47:33,314 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1277076\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "project = hopsworks.login(engine=\"python\")\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8b5e524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1277076/fs/1263683/fg/1638020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 100857/100857 | Elapsed Time: 00:03 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: pm25_hourly_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1277076/jobs/named/pm25_hourly_1_offline_fg_materialization/executions\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1277076/fs/1263683/fg/1668587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 20774/20774 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: pm25_daily_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1277076/jobs/named/pm25_daily_1_offline_fg_materialization/executions\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1277076/fs/1263683/fg/1638021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 303560/303560 | Elapsed Time: 00:15 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: wind_direction_hourly_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1277076/jobs/named/wind_direction_hourly_1_offline_fg_materialization/executions\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1277076/fs/1263683/fg/1668588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 303561/303561 | Elapsed Time: 00:11 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: wind_speed_hourly_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1277076/jobs/named/wind_speed_hourly_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('wind_speed_hourly_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Group 1: Hourly PM2.5 features\n",
    "fg_pm25_hourly = fs.get_or_create_feature_group(\n",
    "    name=\"pm25_hourly\",\n",
    "    description=\"Hourly PM2.5 features with short-term patterns\",\n",
    "    version=1,\n",
    "    primary_key=[\"region\", \"timestamp\"],\n",
    "    partition_key=[\"region\"],\n",
    "    event_time=\"timestamp\",\n",
    ")\n",
    "fg_pm25_hourly.insert(pm25_hourly_df)\n",
    "\n",
    "# Feature Group 2: Daily PM2.5 features\n",
    "fg_pm25_daily = fs.get_or_create_feature_group(\n",
    "    name=\"pm25_daily\",\n",
    "    description=\"Daily PM2.5 aggregations for long-term trends\",\n",
    "    version=1,\n",
    "    primary_key=[\"region\", \"timestamp\"],\n",
    "    partition_key=[\"region\"],\n",
    "    event_time=\"timestamp\",\n",
    ")\n",
    "fg_pm25_daily.insert(pm25_daily_df)\n",
    "\n",
    "# Feature Group 3: Wind Direction features\n",
    "fg_wind_direction = fs.get_or_create_feature_group(\n",
    "    name=\"wind_direction_hourly\",\n",
    "    description=\"Wind direction features with vector components\",\n",
    "    version=1,\n",
    "    primary_key=[\"station_name\", \"timestamp\"],\n",
    "    partition_key=[\"station_name\"],\n",
    "    event_time=\"timestamp\",\n",
    ")\n",
    "fg_wind_direction.insert(wind_direction_df)\n",
    "\n",
    "# Feature Group 4: Wind Speed features\n",
    "fg_wind_speed = fs.get_or_create_feature_group(\n",
    "    name=\"wind_speed_hourly\",\n",
    "    description=\"Wind speed features\",\n",
    "    version=1,\n",
    "    primary_key=[\"station_name\", \"timestamp\"],\n",
    "    partition_key=[\"station_name\"],\n",
    "    event_time=\"timestamp\",\n",
    ")\n",
    "fg_wind_speed.insert(wind_speed_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "air-quality-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
